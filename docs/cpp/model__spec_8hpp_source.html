<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.8.13"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>Turi Create: ml/neural_net/model_spec.hpp Source File</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="navtree.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="resize.js"></script>
<script type="text/javascript" src="navtreedata.js"></script>
<script type="text/javascript" src="navtree.js"></script>
<script type="text/javascript">
  $(document).ready(initResizable);
</script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  <td id="projectalign" style="padding-left: 0.5em;">
   <div id="projectname">Turi Create
   &#160;<span id="projectnumber">4.0</span>
   </div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.8.13 -->
<script type="text/javascript">
var searchBox = new SearchBox("searchBox", "search",false,'Search');
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
</script>
<div id="main-nav"></div>
</div><!-- top -->
<div id="side-nav" class="ui-resizable side-nav-resizable">
  <div id="nav-tree">
    <div id="nav-tree-contents">
      <div id="nav-sync" class="sync"></div>
    </div>
  </div>
  <div id="splitbar" style="-moz-user-select:none;" 
       class="ui-resizable-handle">
  </div>
</div>
<script type="text/javascript">
$(document).ready(function(){initNavTree('model__spec_8hpp_source.html','');});
</script>
<div id="doc-content">
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

<div class="header">
  <div class="headertitle">
<div class="title">model_spec.hpp</div>  </div>
</div><!--header-->
<div class="contents">
<div class="fragment"><div class="line"><a name="l00001"></a><span class="lineno">    1</span>&#160;</div><div class="line"><a name="l00002"></a><span class="lineno">    2</span>&#160;<span class="comment">/* Copyright Â© 2018 Apple Inc. All rights reserved.</span></div><div class="line"><a name="l00003"></a><span class="lineno">    3</span>&#160;<span class="comment"> *</span></div><div class="line"><a name="l00004"></a><span class="lineno">    4</span>&#160;<span class="comment"> * Use of this source code is governed by a BSD-3-clause license that can</span></div><div class="line"><a name="l00005"></a><span class="lineno">    5</span>&#160;<span class="comment"> * be found in the LICENSE.txt file or at https://opensource.org/licenses/BSD-3-Clause</span></div><div class="line"><a name="l00006"></a><span class="lineno">    6</span>&#160;<span class="comment"> */</span></div><div class="line"><a name="l00007"></a><span class="lineno">    7</span>&#160;</div><div class="line"><a name="l00008"></a><span class="lineno">    8</span>&#160;<span class="preprocessor">#ifndef UNITY_TOOLKITS_NEURAL_NET_MODEL_SPEC_HPP_</span></div><div class="line"><a name="l00009"></a><span class="lineno">    9</span>&#160;<span class="preprocessor">#define UNITY_TOOLKITS_NEURAL_NET_MODEL_SPEC_HPP_</span></div><div class="line"><a name="l00010"></a><span class="lineno">   10</span>&#160;</div><div class="line"><a name="l00011"></a><span class="lineno">   11</span>&#160;<span class="preprocessor">#include &lt;array&gt;</span></div><div class="line"><a name="l00012"></a><span class="lineno">   12</span>&#160;<span class="preprocessor">#include &lt;functional&gt;</span></div><div class="line"><a name="l00013"></a><span class="lineno">   13</span>&#160;<span class="preprocessor">#include &lt;memory&gt;</span></div><div class="line"><a name="l00014"></a><span class="lineno">   14</span>&#160;<span class="preprocessor">#include &lt;string&gt;</span></div><div class="line"><a name="l00015"></a><span class="lineno">   15</span>&#160;<span class="preprocessor">#include &lt;vector&gt;</span></div><div class="line"><a name="l00016"></a><span class="lineno">   16</span>&#160;</div><div class="line"><a name="l00017"></a><span class="lineno">   17</span>&#160;<span class="preprocessor">#include &lt;ml/neural_net/float_array.hpp&gt;</span></div><div class="line"><a name="l00018"></a><span class="lineno">   18</span>&#160;<span class="preprocessor">#include &lt;ml/neural_net/weight_init.hpp&gt;</span></div><div class="line"><a name="l00019"></a><span class="lineno">   19</span>&#160;</div><div class="line"><a name="l00020"></a><span class="lineno">   20</span>&#160;<span class="comment">// Forward declare CoreML::Specification::NeuralNetwork in lieu of including</span></div><div class="line"><a name="l00021"></a><span class="lineno">   21</span>&#160;<span class="comment">// problematic protocol buffer headers.</span></div><div class="line"><a name="l00022"></a><span class="lineno">   22</span>&#160;<span class="keyword">namespace </span><a class="code" href="namespaceCoreML.html">CoreML</a> {</div><div class="line"><a name="l00023"></a><span class="lineno">   23</span>&#160;<span class="keyword">namespace </span>Specification {</div><div class="line"><a name="l00024"></a><span class="lineno">   24</span>&#160;<span class="keyword">class </span>NeuralNetwork;</div><div class="line"><a name="l00025"></a><span class="lineno">   25</span>&#160;<span class="keyword">class </span>Pipeline;</div><div class="line"><a name="l00026"></a><span class="lineno">   26</span>&#160;<span class="keyword">class </span>WeightParams;</div><div class="line"><a name="l00027"></a><span class="lineno">   27</span>&#160;}</div><div class="line"><a name="l00028"></a><span class="lineno">   28</span>&#160;}</div><div class="line"><a name="l00029"></a><span class="lineno">   29</span>&#160;</div><div class="line"><a name="l00030"></a><span class="lineno">   30</span>&#160;<span class="keyword">namespace </span><a class="code" href="namespaceturi.html">turi</a> {</div><div class="line"><a name="l00031"></a><span class="lineno">   31</span>&#160;<span class="keyword">namespace </span>neural_net {</div><div class="line"><a name="l00032"></a><span class="lineno">   32</span>&#160;<span class="comment"></span></div><div class="line"><a name="l00033"></a><span class="lineno">   33</span>&#160;<span class="comment">/**</span></div><div class="line"><a name="l00034"></a><span class="lineno">   34</span>&#160;<span class="comment"> * Representation for a neural-network model (structure and parameters),</span></div><div class="line"><a name="l00035"></a><span class="lineno">   35</span>&#160;<span class="comment"> * optimized for convenient export to CoreML.</span></div><div class="line"><a name="l00036"></a><span class="lineno">   36</span>&#160;<span class="comment"> *</span></div><div class="line"><a name="l00037"></a><span class="lineno">   37</span>&#160;<span class="comment"> * This class just wraps CoreML::Specification::NeuralNetwork, helping to</span></div><div class="line"><a name="l00038"></a><span class="lineno">   38</span>&#160;<span class="comment"> * insulate toolkits from protobuf code.</span></div><div class="line"><a name="l00039"></a><span class="lineno">   39</span>&#160;<span class="comment"> */</span></div><div class="line"><a name="l00040"></a><span class="lineno"><a class="line" href="classturi_1_1neural__net_1_1model__spec.html">   40</a></span>&#160;<span class="keyword">class </span><a class="code" href="classturi_1_1neural__net_1_1model__spec.html">model_spec</a> {</div><div class="line"><a name="l00041"></a><span class="lineno">   41</span>&#160;<span class="keyword">public</span>:</div><div class="line"><a name="l00042"></a><span class="lineno">   42</span>&#160;<span class="comment"></span></div><div class="line"><a name="l00043"></a><span class="lineno">   43</span>&#160;<span class="comment">  /** Parameter for convolution and pooling layers. */</span></div><div class="line"><a name="l00044"></a><span class="lineno"><a class="line" href="classturi_1_1neural__net_1_1model__spec.html#a0d1aa5b0fcc3c11248e0a2e33c49ff4f">   44</a></span>&#160;  <span class="keyword">enum class</span> <a class="code" href="classturi_1_1neural__net_1_1model__spec.html#a0d1aa5b0fcc3c11248e0a2e33c49ff4f">padding_type</a> {</div><div class="line"><a name="l00045"></a><span class="lineno">   45</span>&#160;    VALID,</div><div class="line"><a name="l00046"></a><span class="lineno">   46</span>&#160;    SAME,</div><div class="line"><a name="l00047"></a><span class="lineno">   47</span>&#160;  };</div><div class="line"><a name="l00048"></a><span class="lineno">   48</span>&#160;<span class="comment"></span></div><div class="line"><a name="l00049"></a><span class="lineno">   49</span>&#160;<span class="comment">  /** Parameter for the padding layer */</span></div><div class="line"><a name="l00050"></a><span class="lineno"><a class="line" href="classturi_1_1neural__net_1_1model__spec.html#a972ab38f4986dabfac28beaee2ae01ce">   50</a></span>&#160;  <span class="keyword">enum class</span> <a class="code" href="classturi_1_1neural__net_1_1model__spec.html#a972ab38f4986dabfac28beaee2ae01ce">padding_policy</a> {</div><div class="line"><a name="l00051"></a><span class="lineno">   51</span>&#160;    REFLECTIVE,</div><div class="line"><a name="l00052"></a><span class="lineno">   52</span>&#160;    REPLICATION,</div><div class="line"><a name="l00053"></a><span class="lineno">   53</span>&#160;    ZERO,</div><div class="line"><a name="l00054"></a><span class="lineno">   54</span>&#160;  };</div><div class="line"><a name="l00055"></a><span class="lineno">   55</span>&#160;<span class="comment"></span></div><div class="line"><a name="l00056"></a><span class="lineno">   56</span>&#160;<span class="comment">  /** Parameter for pooling types. */</span></div><div class="line"><a name="l00057"></a><span class="lineno"><a class="line" href="classturi_1_1neural__net_1_1model__spec.html#ae6369ecdfff80b58bc29d092960d7248">   57</a></span>&#160;  <span class="keyword">enum class</span> <a class="code" href="classturi_1_1neural__net_1_1model__spec.html#ae6369ecdfff80b58bc29d092960d7248">pooling_type</a> { MAX, AVERAGE, L2 };</div><div class="line"><a name="l00058"></a><span class="lineno">   58</span>&#160;<span class="comment"></span></div><div class="line"><a name="l00059"></a><span class="lineno">   59</span>&#160;<span class="comment">  /**</span></div><div class="line"><a name="l00060"></a><span class="lineno">   60</span>&#160;<span class="comment">   * Creates an empty model_spec (with no layers).</span></div><div class="line"><a name="l00061"></a><span class="lineno">   61</span>&#160;<span class="comment">   */</span></div><div class="line"><a name="l00062"></a><span class="lineno">   62</span>&#160;  <a class="code" href="classturi_1_1neural__net_1_1model__spec.html">model_spec</a>();</div><div class="line"><a name="l00063"></a><span class="lineno">   63</span>&#160;<span class="comment"></span></div><div class="line"><a name="l00064"></a><span class="lineno">   64</span>&#160;<span class="comment">  /**</span></div><div class="line"><a name="l00065"></a><span class="lineno">   65</span>&#160;<span class="comment">   * Initializes a model_spec from a NeuralNetwork proto.</span></div><div class="line"><a name="l00066"></a><span class="lineno">   66</span>&#160;<span class="comment">   */</span></div><div class="line"><a name="l00067"></a><span class="lineno">   67</span>&#160;  <a class="code" href="classturi_1_1neural__net_1_1model__spec.html">model_spec</a>(<span class="keyword">const</span> CoreML::Specification::NeuralNetwork&amp; nn_model);</div><div class="line"><a name="l00068"></a><span class="lineno">   68</span>&#160;<span class="comment"></span></div><div class="line"><a name="l00069"></a><span class="lineno">   69</span>&#160;<span class="comment">  /**</span></div><div class="line"><a name="l00070"></a><span class="lineno">   70</span>&#160;<span class="comment">   * Initializes a model_spec from the top-level NeuralNetwork found inside a</span></div><div class="line"><a name="l00071"></a><span class="lineno">   71</span>&#160;<span class="comment">   * CoreML model specification on disk.</span></div><div class="line"><a name="l00072"></a><span class="lineno">   72</span>&#160;<span class="comment">   *</span></div><div class="line"><a name="l00073"></a><span class="lineno">   73</span>&#160;<span class="comment">   * \param mlmodel_path Path to a CoreM::Specification::Model proto on disk.</span></div><div class="line"><a name="l00074"></a><span class="lineno">   74</span>&#160;<span class="comment">   * \throw If the indicated path could not be read or parsed.</span></div><div class="line"><a name="l00075"></a><span class="lineno">   75</span>&#160;<span class="comment">   */</span></div><div class="line"><a name="l00076"></a><span class="lineno">   76</span>&#160;  <a class="code" href="classturi_1_1neural__net_1_1model__spec.html">model_spec</a>(<span class="keyword">const</span> std::string&amp; mlmodel_path);</div><div class="line"><a name="l00077"></a><span class="lineno">   77</span>&#160;</div><div class="line"><a name="l00078"></a><span class="lineno">   78</span>&#160;  <span class="comment">// Declared here and defined in the .cpp file just to prevent the implicit</span></div><div class="line"><a name="l00079"></a><span class="lineno">   79</span>&#160;  <span class="comment">// default destructor from attempting (and failing) to instantiate</span></div><div class="line"><a name="l00080"></a><span class="lineno">   80</span>&#160;  <span class="comment">// std::unique_ptr&lt;NeuralNetwork&gt;::~unique_ptr()</span></div><div class="line"><a name="l00081"></a><span class="lineno">   81</span>&#160;  <a class="code" href="classturi_1_1neural__net_1_1model__spec.html">model_spec</a>(<a class="code" href="classturi_1_1neural__net_1_1model__spec.html">model_spec</a>&amp;&amp;);</div><div class="line"><a name="l00082"></a><span class="lineno">   82</span>&#160;  <a class="code" href="classturi_1_1neural__net_1_1model__spec.html">model_spec</a>&amp; operator=(<a class="code" href="classturi_1_1neural__net_1_1model__spec.html">model_spec</a>&amp;&amp;);</div><div class="line"><a name="l00083"></a><span class="lineno">   83</span>&#160;  ~<a class="code" href="classturi_1_1neural__net_1_1model__spec.html">model_spec</a>();</div><div class="line"><a name="l00084"></a><span class="lineno">   84</span>&#160;<span class="comment"></span></div><div class="line"><a name="l00085"></a><span class="lineno">   85</span>&#160;<span class="comment">  /**</span></div><div class="line"><a name="l00086"></a><span class="lineno">   86</span>&#160;<span class="comment">   * Exposes the underlying CoreML proto.</span></div><div class="line"><a name="l00087"></a><span class="lineno">   87</span>&#160;<span class="comment">   */</span></div><div class="line"><a name="l00088"></a><span class="lineno"><a class="line" href="classturi_1_1neural__net_1_1model__spec.html#a4d8bdc11e8d0b74a416a9ccfba8cb4c8">   88</a></span>&#160;  <span class="keyword">const</span> CoreML::Specification::NeuralNetwork&amp; <a class="code" href="classturi_1_1neural__net_1_1model__spec.html#a4d8bdc11e8d0b74a416a9ccfba8cb4c8">get_coreml_spec</a>()<span class="keyword"> const </span>{</div><div class="line"><a name="l00089"></a><span class="lineno">   89</span>&#160;    <span class="keywordflow">return</span> *impl_;</div><div class="line"><a name="l00090"></a><span class="lineno">   90</span>&#160;  }</div><div class="line"><a name="l00091"></a><span class="lineno">   91</span>&#160;<span class="comment"></span></div><div class="line"><a name="l00092"></a><span class="lineno">   92</span>&#160;<span class="comment">  /**</span></div><div class="line"><a name="l00093"></a><span class="lineno">   93</span>&#160;<span class="comment">   * Transfer ownership of the underlying CoreML proto, invalidating the current</span></div><div class="line"><a name="l00094"></a><span class="lineno">   94</span>&#160;<span class="comment">   * instance (leaving it in a &quot;moved-from&quot; state).</span></div><div class="line"><a name="l00095"></a><span class="lineno">   95</span>&#160;<span class="comment">   *</span></div><div class="line"><a name="l00096"></a><span class="lineno">   96</span>&#160;<span class="comment">   * (Note that this method may only be invoked from a model_spec&amp;&amp;)</span></div><div class="line"><a name="l00097"></a><span class="lineno">   97</span>&#160;<span class="comment">   */</span></div><div class="line"><a name="l00098"></a><span class="lineno">   98</span>&#160;  std::unique_ptr&lt;CoreML::Specification::NeuralNetwork&gt; move_coreml_spec() &amp;&amp;;</div><div class="line"><a name="l00099"></a><span class="lineno">   99</span>&#160;<span class="comment"></span></div><div class="line"><a name="l00100"></a><span class="lineno">  100</span>&#160;<span class="comment">  /**</span></div><div class="line"><a name="l00101"></a><span class="lineno">  101</span>&#160;<span class="comment">   * Creates a shared_float_array view (weak reference) into the parameters of</span></div><div class="line"><a name="l00102"></a><span class="lineno">  102</span>&#160;<span class="comment">   * the model, indexed by layer name.</span></div><div class="line"><a name="l00103"></a><span class="lineno">  103</span>&#160;<span class="comment">   *</span></div><div class="line"><a name="l00104"></a><span class="lineno">  104</span>&#160;<span class="comment">   * \return A dictionary whose keys are of the form</span></div><div class="line"><a name="l00105"></a><span class="lineno">  105</span>&#160;<span class="comment">   *         &quot;$layername_$paramname&quot;. The layer names are taken from the name</span></div><div class="line"><a name="l00106"></a><span class="lineno">  106</span>&#160;<span class="comment">   *         field of each NeuralNetworkLayer containing a supported layer. The</span></div><div class="line"><a name="l00107"></a><span class="lineno">  107</span>&#160;<span class="comment">   *         supported layers are ConvolutionLayerParams (with params &quot;weight&quot;</span></div><div class="line"><a name="l00108"></a><span class="lineno">  108</span>&#160;<span class="comment">   *         (in NCHW order) and &quot;bias&quot;) and BatchnormLayerParams (with params</span></div><div class="line"><a name="l00109"></a><span class="lineno">  109</span>&#160;<span class="comment">   *         &quot;gamma&quot;, &quot;beta&quot;, &quot;running_mean&quot;, and &quot;running_var&quot;).</span></div><div class="line"><a name="l00110"></a><span class="lineno">  110</span>&#160;<span class="comment">   * \throw If a NeuralNetworkLayer in the specification seems malformed</span></div><div class="line"><a name="l00111"></a><span class="lineno">  111</span>&#160;<span class="comment">   *        (e.g. WeightParams with size inconsistent with declared layer</span></div><div class="line"><a name="l00112"></a><span class="lineno">  112</span>&#160;<span class="comment">   *        shape).</span></div><div class="line"><a name="l00113"></a><span class="lineno">  113</span>&#160;<span class="comment">   *</span></div><div class="line"><a name="l00114"></a><span class="lineno">  114</span>&#160;<span class="comment">   * To avoid copying data, the data backing the shared_float_array instances in</span></div><div class="line"><a name="l00115"></a><span class="lineno">  115</span>&#160;<span class="comment">   * the return value will only remain valid for the lifetime of this instance!</span></div><div class="line"><a name="l00116"></a><span class="lineno">  116</span>&#160;<span class="comment">   */</span></div><div class="line"><a name="l00117"></a><span class="lineno">  117</span>&#160;  float_array_map export_params_view() <span class="keyword">const</span>;</div><div class="line"><a name="l00118"></a><span class="lineno">  118</span>&#160;<span class="comment"></span></div><div class="line"><a name="l00119"></a><span class="lineno">  119</span>&#160;<span class="comment">  /**</span></div><div class="line"><a name="l00120"></a><span class="lineno">  120</span>&#160;<span class="comment">   * Overwrites existing WeightParams values using the provided float_array</span></div><div class="line"><a name="l00121"></a><span class="lineno">  121</span>&#160;<span class="comment">   * values.</span></div><div class="line"><a name="l00122"></a><span class="lineno">  122</span>&#160;<span class="comment">   *</span></div><div class="line"><a name="l00123"></a><span class="lineno">  123</span>&#160;<span class="comment">   * \param weights A dictionary whose keys follow the same naming scheme used</span></div><div class="line"><a name="l00124"></a><span class="lineno">  124</span>&#160;<span class="comment">   *                by `export_params_view`.</span></div><div class="line"><a name="l00125"></a><span class="lineno">  125</span>&#160;<span class="comment">   * \param use_quantization If true, weights are stored in half precision.</span></div><div class="line"><a name="l00126"></a><span class="lineno">  126</span>&#160;<span class="comment">   * \throw If a float_array&#39;s shape does not match the corresponding</span></div><div class="line"><a name="l00127"></a><span class="lineno">  127</span>&#160;<span class="comment">   *        NeuralNetworkLayer.</span></div><div class="line"><a name="l00128"></a><span class="lineno">  128</span>&#160;<span class="comment">   */</span></div><div class="line"><a name="l00129"></a><span class="lineno">  129</span>&#160;  <span class="keywordtype">void</span> update_params(<span class="keyword">const</span> float_array_map&amp; weights, <span class="keywordtype">bool</span> use_quantization = <span class="keyword">false</span>);</div><div class="line"><a name="l00130"></a><span class="lineno">  130</span>&#160;<span class="comment"></span></div><div class="line"><a name="l00131"></a><span class="lineno">  131</span>&#160;<span class="comment">  /**</span></div><div class="line"><a name="l00132"></a><span class="lineno">  132</span>&#160;<span class="comment">   * Determines whether the neural network contains a layer with the given</span></div><div class="line"><a name="l00133"></a><span class="lineno">  133</span>&#160;<span class="comment">   * output name.</span></div><div class="line"><a name="l00134"></a><span class="lineno">  134</span>&#160;<span class="comment">   *</span></div><div class="line"><a name="l00135"></a><span class="lineno">  135</span>&#160;<span class="comment">   * In general, it is only safe to add a new layer that takes a named input if</span></div><div class="line"><a name="l00136"></a><span class="lineno">  136</span>&#160;<span class="comment">   * this method returns true for that name.</span></div><div class="line"><a name="l00137"></a><span class="lineno">  137</span>&#160;<span class="comment">   */</span></div><div class="line"><a name="l00138"></a><span class="lineno">  138</span>&#160;  <span class="keywordtype">bool</span> has_layer_output(<span class="keyword">const</span> std::string&amp; layer_name) <span class="keyword">const</span>;</div><div class="line"><a name="l00139"></a><span class="lineno">  139</span>&#160;<span class="comment"></span></div><div class="line"><a name="l00140"></a><span class="lineno">  140</span>&#160;<span class="comment">  /**</span></div><div class="line"><a name="l00141"></a><span class="lineno">  141</span>&#160;<span class="comment">   * Appends a ReLU activation layer.</span></div><div class="line"><a name="l00142"></a><span class="lineno">  142</span>&#160;<span class="comment">   *</span></div><div class="line"><a name="l00143"></a><span class="lineno">  143</span>&#160;<span class="comment">   * \param name The name of the layer and its output</span></div><div class="line"><a name="l00144"></a><span class="lineno">  144</span>&#160;<span class="comment">   * \param input The name of the layer&#39;s input</span></div><div class="line"><a name="l00145"></a><span class="lineno">  145</span>&#160;<span class="comment">   */</span></div><div class="line"><a name="l00146"></a><span class="lineno">  146</span>&#160;  <span class="keywordtype">void</span> add_relu(<span class="keyword">const</span> std::string&amp; name, <span class="keyword">const</span> std::string&amp; input);</div><div class="line"><a name="l00147"></a><span class="lineno">  147</span>&#160;<span class="comment"></span></div><div class="line"><a name="l00148"></a><span class="lineno">  148</span>&#160;<span class="comment">  /**</span></div><div class="line"><a name="l00149"></a><span class="lineno">  149</span>&#160;<span class="comment">   * Appends a leaky ReLU activation layer.</span></div><div class="line"><a name="l00150"></a><span class="lineno">  150</span>&#160;<span class="comment">   *</span></div><div class="line"><a name="l00151"></a><span class="lineno">  151</span>&#160;<span class="comment">   * \param name The name of the layer and its output</span></div><div class="line"><a name="l00152"></a><span class="lineno">  152</span>&#160;<span class="comment">   * \param input The name of the layer&#39;s input</span></div><div class="line"><a name="l00153"></a><span class="lineno">  153</span>&#160;<span class="comment">   * \param alpha Multiplied to negative inputs</span></div><div class="line"><a name="l00154"></a><span class="lineno">  154</span>&#160;<span class="comment">   */</span></div><div class="line"><a name="l00155"></a><span class="lineno">  155</span>&#160;  <span class="keywordtype">void</span> add_leakyrelu(<span class="keyword">const</span> std::string&amp; name, <span class="keyword">const</span> std::string&amp; input,</div><div class="line"><a name="l00156"></a><span class="lineno">  156</span>&#160;                     <span class="keywordtype">float</span> alpha);</div><div class="line"><a name="l00157"></a><span class="lineno">  157</span>&#160;<span class="comment"></span></div><div class="line"><a name="l00158"></a><span class="lineno">  158</span>&#160;<span class="comment">  /**</span></div><div class="line"><a name="l00159"></a><span class="lineno">  159</span>&#160;<span class="comment">   * Appends a sigmoid activation layer.</span></div><div class="line"><a name="l00160"></a><span class="lineno">  160</span>&#160;<span class="comment">   *</span></div><div class="line"><a name="l00161"></a><span class="lineno">  161</span>&#160;<span class="comment">   * \param name The name of the layer and its output</span></div><div class="line"><a name="l00162"></a><span class="lineno">  162</span>&#160;<span class="comment">   * \param input The name of the layer&#39;s input</span></div><div class="line"><a name="l00163"></a><span class="lineno">  163</span>&#160;<span class="comment">   */</span></div><div class="line"><a name="l00164"></a><span class="lineno">  164</span>&#160;  <span class="keywordtype">void</span> add_sigmoid(<span class="keyword">const</span> std::string&amp; name, <span class="keyword">const</span> std::string&amp; input);</div><div class="line"><a name="l00165"></a><span class="lineno">  165</span>&#160;<span class="comment"></span></div><div class="line"><a name="l00166"></a><span class="lineno">  166</span>&#160;<span class="comment">  /**</span></div><div class="line"><a name="l00167"></a><span class="lineno">  167</span>&#160;<span class="comment">   * Appends a pooling layer.</span></div><div class="line"><a name="l00168"></a><span class="lineno">  168</span>&#160;<span class="comment">   * By default, it&#39;s a max pooling layer.</span></div><div class="line"><a name="l00169"></a><span class="lineno">  169</span>&#160;<span class="comment">   *</span></div><div class="line"><a name="l00170"></a><span class="lineno">  170</span>&#160;<span class="comment">   * It can be of type:</span></div><div class="line"><a name="l00171"></a><span class="lineno">  171</span>&#160;<span class="comment">   *      - MAX</span></div><div class="line"><a name="l00172"></a><span class="lineno">  172</span>&#160;<span class="comment">   *      - AVERAGE</span></div><div class="line"><a name="l00173"></a><span class="lineno">  173</span>&#160;<span class="comment">   *      - L2</span></div><div class="line"><a name="l00174"></a><span class="lineno">  174</span>&#160;<span class="comment">   *</span></div><div class="line"><a name="l00175"></a><span class="lineno">  175</span>&#160;<span class="comment">   * \param pooling this sets the type of pooling this layer performs.</span></div><div class="line"><a name="l00176"></a><span class="lineno">  176</span>&#160;<span class="comment">   * \param use_poolexcludepadding padded values are excluded from the</span></div><div class="line"><a name="l00177"></a><span class="lineno">  177</span>&#160;<span class="comment">   * count (denominator) when computing average pooling.</span></div><div class="line"><a name="l00178"></a><span class="lineno">  178</span>&#160;<span class="comment">   */</span></div><div class="line"><a name="l00179"></a><span class="lineno">  179</span>&#160;  <span class="keywordtype">void</span> add_pooling(<span class="keyword">const</span> std::string&amp; name, <span class="keyword">const</span> std::string&amp; input, <span class="keywordtype">size_t</span> kernel_height,</div><div class="line"><a name="l00180"></a><span class="lineno">  180</span>&#160;                   <span class="keywordtype">size_t</span> kernel_width, <span class="keywordtype">size_t</span> stride_h, <span class="keywordtype">size_t</span> stride_w, <a class="code" href="classturi_1_1neural__net_1_1model__spec.html#a0d1aa5b0fcc3c11248e0a2e33c49ff4f">padding_type</a> padding,</div><div class="line"><a name="l00181"></a><span class="lineno">  181</span>&#160;                   <span class="keywordtype">bool</span> use_poolexcludepadding = <span class="keyword">false</span>, <a class="code" href="classturi_1_1neural__net_1_1model__spec.html#ae6369ecdfff80b58bc29d092960d7248">pooling_type</a> pooling = pooling_type::MAX);</div><div class="line"><a name="l00182"></a><span class="lineno">  182</span>&#160;<span class="comment"></span></div><div class="line"><a name="l00183"></a><span class="lineno">  183</span>&#160;<span class="comment">  /**</span></div><div class="line"><a name="l00184"></a><span class="lineno">  184</span>&#160;<span class="comment">   * Appends a convolution layer.</span></div><div class="line"><a name="l00185"></a><span class="lineno">  185</span>&#160;<span class="comment">   *</span></div><div class="line"><a name="l00186"></a><span class="lineno">  186</span>&#160;<span class="comment">   * \param name The name of the layer and its output</span></div><div class="line"><a name="l00187"></a><span class="lineno">  187</span>&#160;<span class="comment">   * \param input The name of the layer&#39;s input</span></div><div class="line"><a name="l00188"></a><span class="lineno">  188</span>&#160;<span class="comment">   * \param num_output_channels The number of distinct filters in this layer</span></div><div class="line"><a name="l00189"></a><span class="lineno">  189</span>&#160;<span class="comment">   * \param num_kernel_channels The number of input features per &quot;pixel&quot;</span></div><div class="line"><a name="l00190"></a><span class="lineno">  190</span>&#160;<span class="comment">   * \param kernel_size The height and width of the kernel</span></div><div class="line"><a name="l00191"></a><span class="lineno">  191</span>&#160;<span class="comment">   * \param weight_initializer_fn Callback used to initialize the conv weights</span></div><div class="line"><a name="l00192"></a><span class="lineno">  192</span>&#160;<span class="comment">   * \param bias_initializer_fn Callback used to initialize the conv bias. If</span></div><div class="line"><a name="l00193"></a><span class="lineno">  193</span>&#160;<span class="comment">   *                            nullptr, then no bias vector is set.</span></div><div class="line"><a name="l00194"></a><span class="lineno">  194</span>&#160;<span class="comment">   */</span></div><div class="line"><a name="l00195"></a><span class="lineno">  195</span>&#160;  <span class="keywordtype">void</span> add_convolution(<span class="keyword">const</span> std::string&amp; name, <span class="keyword">const</span> std::string&amp; input,</div><div class="line"><a name="l00196"></a><span class="lineno">  196</span>&#160;                       <span class="keywordtype">size_t</span> num_output_channels, <span class="keywordtype">size_t</span> num_kernel_channels,</div><div class="line"><a name="l00197"></a><span class="lineno">  197</span>&#160;                       <span class="keywordtype">size_t</span> kernel_height, <span class="keywordtype">size_t</span> kernel_width,</div><div class="line"><a name="l00198"></a><span class="lineno">  198</span>&#160;                       <span class="keywordtype">size_t</span> stride_h, <span class="keywordtype">size_t</span> stride_w, <a class="code" href="classturi_1_1neural__net_1_1model__spec.html#a0d1aa5b0fcc3c11248e0a2e33c49ff4f">padding_type</a> padding,</div><div class="line"><a name="l00199"></a><span class="lineno">  199</span>&#160;                       weight_initializer weight_initializer_fn,</div><div class="line"><a name="l00200"></a><span class="lineno">  200</span>&#160;                       weight_initializer bias_initializer_fn = <span class="keyword">nullptr</span>);</div><div class="line"><a name="l00201"></a><span class="lineno">  201</span>&#160;<span class="comment"></span></div><div class="line"><a name="l00202"></a><span class="lineno">  202</span>&#160;<span class="comment">  /**</span></div><div class="line"><a name="l00203"></a><span class="lineno">  203</span>&#160;<span class="comment">   * Appends a padding layer.</span></div><div class="line"><a name="l00204"></a><span class="lineno">  204</span>&#160;<span class="comment">   *</span></div><div class="line"><a name="l00205"></a><span class="lineno">  205</span>&#160;<span class="comment">   * \param name The name of the layer and its output</span></div><div class="line"><a name="l00206"></a><span class="lineno">  206</span>&#160;<span class="comment">   * \param input The name of the layer&#39;s input</span></div><div class="line"><a name="l00207"></a><span class="lineno">  207</span>&#160;<span class="comment">   * \param padding_top The padding on the top</span></div><div class="line"><a name="l00208"></a><span class="lineno">  208</span>&#160;<span class="comment">   * \param padding_bottom The padding on the bottom</span></div><div class="line"><a name="l00209"></a><span class="lineno">  209</span>&#160;<span class="comment">   * \param padding_left The padding to the left</span></div><div class="line"><a name="l00210"></a><span class="lineno">  210</span>&#160;<span class="comment">   * \param padding_right The padding to the right</span></div><div class="line"><a name="l00211"></a><span class="lineno">  211</span>&#160;<span class="comment">   * \param policy The padding policy of zero, reflective, or replication</span></div><div class="line"><a name="l00212"></a><span class="lineno">  212</span>&#160;<span class="comment">   */</span></div><div class="line"><a name="l00213"></a><span class="lineno">  213</span>&#160;  <span class="keywordtype">void</span> add_padding(<span class="keyword">const</span> std::string&amp; name, <span class="keyword">const</span> std::string&amp; input,</div><div class="line"><a name="l00214"></a><span class="lineno">  214</span>&#160;                   <span class="keywordtype">size_t</span> padding_top, <span class="keywordtype">size_t</span> padding_bottom,</div><div class="line"><a name="l00215"></a><span class="lineno">  215</span>&#160;                   <span class="keywordtype">size_t</span> padding_left, <span class="keywordtype">size_t</span> padding_right,</div><div class="line"><a name="l00216"></a><span class="lineno">  216</span>&#160;                   <a class="code" href="classturi_1_1neural__net_1_1model__spec.html#a972ab38f4986dabfac28beaee2ae01ce">padding_policy</a> policy = padding_policy::REFLECTIVE);</div><div class="line"><a name="l00217"></a><span class="lineno">  217</span>&#160;<span class="comment"></span></div><div class="line"><a name="l00218"></a><span class="lineno">  218</span>&#160;<span class="comment">  /**</span></div><div class="line"><a name="l00219"></a><span class="lineno">  219</span>&#160;<span class="comment">   * Appends an upsampling layer.</span></div><div class="line"><a name="l00220"></a><span class="lineno">  220</span>&#160;<span class="comment">   *</span></div><div class="line"><a name="l00221"></a><span class="lineno">  221</span>&#160;<span class="comment">   * \param name The name of the layer and its output</span></div><div class="line"><a name="l00222"></a><span class="lineno">  222</span>&#160;<span class="comment">   * \param input The name of the layer&#39;s input</span></div><div class="line"><a name="l00223"></a><span class="lineno">  223</span>&#160;<span class="comment">   * \param scaling_x The upsample scale on the x axis</span></div><div class="line"><a name="l00224"></a><span class="lineno">  224</span>&#160;<span class="comment">   * \param scaling_y The upsample scale on the y axis</span></div><div class="line"><a name="l00225"></a><span class="lineno">  225</span>&#160;<span class="comment">   */</span></div><div class="line"><a name="l00226"></a><span class="lineno">  226</span>&#160;  <span class="keywordtype">void</span> add_upsampling(<span class="keyword">const</span> std::string&amp; name, <span class="keyword">const</span> std::string&amp; input,</div><div class="line"><a name="l00227"></a><span class="lineno">  227</span>&#160;                      <span class="keywordtype">size_t</span> scaling_x, <span class="keywordtype">size_t</span> scaling_y);</div><div class="line"><a name="l00228"></a><span class="lineno">  228</span>&#160;<span class="comment"></span></div><div class="line"><a name="l00229"></a><span class="lineno">  229</span>&#160;<span class="comment">  /**</span></div><div class="line"><a name="l00230"></a><span class="lineno">  230</span>&#160;<span class="comment">   * Appends an inner-product (dense, fully connected) layer.</span></div><div class="line"><a name="l00231"></a><span class="lineno">  231</span>&#160;<span class="comment">   *</span></div><div class="line"><a name="l00232"></a><span class="lineno">  232</span>&#160;<span class="comment">   * \param name The name of the layer and its output</span></div><div class="line"><a name="l00233"></a><span class="lineno">  233</span>&#160;<span class="comment">   * \param input The name of the layer&#39;s input</span></div><div class="line"><a name="l00234"></a><span class="lineno">  234</span>&#160;<span class="comment">   * \param num_output_channels Size of the output vector</span></div><div class="line"><a name="l00235"></a><span class="lineno">  235</span>&#160;<span class="comment">   * \param num_input_channels Size of the input vector</span></div><div class="line"><a name="l00236"></a><span class="lineno">  236</span>&#160;<span class="comment">   * \param weight_initializer_fn Callback used to initialize the weights</span></div><div class="line"><a name="l00237"></a><span class="lineno">  237</span>&#160;<span class="comment">   * \param bias_initializer_fn Callback used to initialize the bias. If</span></div><div class="line"><a name="l00238"></a><span class="lineno">  238</span>&#160;<span class="comment">   *            nullptr, then no bias vector is set.</span></div><div class="line"><a name="l00239"></a><span class="lineno">  239</span>&#160;<span class="comment">   */</span></div><div class="line"><a name="l00240"></a><span class="lineno">  240</span>&#160;  <span class="keywordtype">void</span> add_inner_product(<span class="keyword">const</span> std::string&amp; name, <span class="keyword">const</span> std::string&amp; input,</div><div class="line"><a name="l00241"></a><span class="lineno">  241</span>&#160;                         <span class="keywordtype">size_t</span> num_output_channels, <span class="keywordtype">size_t</span> num_input_channels,</div><div class="line"><a name="l00242"></a><span class="lineno">  242</span>&#160;                         weight_initializer weight_initializer_fn,</div><div class="line"><a name="l00243"></a><span class="lineno">  243</span>&#160;                         weight_initializer bias_initializer_fn = <span class="keyword">nullptr</span>);</div><div class="line"><a name="l00244"></a><span class="lineno">  244</span>&#160;<span class="comment"></span></div><div class="line"><a name="l00245"></a><span class="lineno">  245</span>&#160;<span class="comment">  /**</span></div><div class="line"><a name="l00246"></a><span class="lineno">  246</span>&#160;<span class="comment">   * Appends a batch norm layer.</span></div><div class="line"><a name="l00247"></a><span class="lineno">  247</span>&#160;<span class="comment">   *</span></div><div class="line"><a name="l00248"></a><span class="lineno">  248</span>&#160;<span class="comment">   * The beta and mean parameters are initialized to 0.f; the gamma and variance</span></div><div class="line"><a name="l00249"></a><span class="lineno">  249</span>&#160;<span class="comment">   * parameters are initialized to 1.f</span></div><div class="line"><a name="l00250"></a><span class="lineno">  250</span>&#160;<span class="comment">   *</span></div><div class="line"><a name="l00251"></a><span class="lineno">  251</span>&#160;<span class="comment">   * \param name The name of the layer and its output</span></div><div class="line"><a name="l00252"></a><span class="lineno">  252</span>&#160;<span class="comment">   * \param input The name of the layer&#39;s input</span></div><div class="line"><a name="l00253"></a><span class="lineno">  253</span>&#160;<span class="comment">   * \param num_channels The C dimension of the input and output</span></div><div class="line"><a name="l00254"></a><span class="lineno">  254</span>&#160;<span class="comment">   * \param epsilon Added to the variance for each input before normalizing</span></div><div class="line"><a name="l00255"></a><span class="lineno">  255</span>&#160;<span class="comment">   */</span></div><div class="line"><a name="l00256"></a><span class="lineno">  256</span>&#160;  <span class="keywordtype">void</span> add_batchnorm(<span class="keyword">const</span> std::string&amp; name, <span class="keyword">const</span> std::string&amp; input,</div><div class="line"><a name="l00257"></a><span class="lineno">  257</span>&#160;                     <span class="keywordtype">size_t</span> num_channels, <span class="keywordtype">float</span> epsilon);</div><div class="line"><a name="l00258"></a><span class="lineno">  258</span>&#160;<span class="comment"></span></div><div class="line"><a name="l00259"></a><span class="lineno">  259</span>&#160;<span class="comment">  /**</span></div><div class="line"><a name="l00260"></a><span class="lineno">  260</span>&#160;<span class="comment">   * Appends an instance norm layer.</span></div><div class="line"><a name="l00261"></a><span class="lineno">  261</span>&#160;<span class="comment">   *</span></div><div class="line"><a name="l00262"></a><span class="lineno">  262</span>&#160;<span class="comment">   * The beta is initialized to 0.f; the gamma is initialized to 1.f</span></div><div class="line"><a name="l00263"></a><span class="lineno">  263</span>&#160;<span class="comment">   *</span></div><div class="line"><a name="l00264"></a><span class="lineno">  264</span>&#160;<span class="comment">   * \param name The name of the layer and its output</span></div><div class="line"><a name="l00265"></a><span class="lineno">  265</span>&#160;<span class="comment">   * \param input The name of the layer&#39;s input</span></div><div class="line"><a name="l00266"></a><span class="lineno">  266</span>&#160;<span class="comment">   * \param num_channels The C dimension of the input and output</span></div><div class="line"><a name="l00267"></a><span class="lineno">  267</span>&#160;<span class="comment">   * \param epsilon Added to the variance for each input before normalizing</span></div><div class="line"><a name="l00268"></a><span class="lineno">  268</span>&#160;<span class="comment">   */</span></div><div class="line"><a name="l00269"></a><span class="lineno">  269</span>&#160;  <span class="keywordtype">void</span> add_instancenorm(<span class="keyword">const</span> std::string&amp; name, <span class="keyword">const</span> std::string&amp; input,</div><div class="line"><a name="l00270"></a><span class="lineno">  270</span>&#160;                        <span class="keywordtype">size_t</span> num_channels, <span class="keywordtype">float</span> epsilon);</div><div class="line"><a name="l00271"></a><span class="lineno">  271</span>&#160;<span class="comment"></span></div><div class="line"><a name="l00272"></a><span class="lineno">  272</span>&#160;<span class="comment">  /**</span></div><div class="line"><a name="l00273"></a><span class="lineno">  273</span>&#160;<span class="comment">   * Appends a layer that concatenates its inputs along the channel axis.</span></div><div class="line"><a name="l00274"></a><span class="lineno">  274</span>&#160;<span class="comment">   *</span></div><div class="line"><a name="l00275"></a><span class="lineno">  275</span>&#160;<span class="comment">   * \param name The name of the layer and its output</span></div><div class="line"><a name="l00276"></a><span class="lineno">  276</span>&#160;<span class="comment">   * \param inputs The names of the layer&#39;s inputs</span></div><div class="line"><a name="l00277"></a><span class="lineno">  277</span>&#160;<span class="comment">   */</span></div><div class="line"><a name="l00278"></a><span class="lineno">  278</span>&#160;  <span class="keywordtype">void</span> add_channel_concat(<span class="keyword">const</span> std::string&amp; name,</div><div class="line"><a name="l00279"></a><span class="lineno">  279</span>&#160;                          <span class="keyword">const</span> std::vector&lt;std::string&gt;&amp; inputs);</div><div class="line"><a name="l00280"></a><span class="lineno">  280</span>&#160;<span class="comment"></span></div><div class="line"><a name="l00281"></a><span class="lineno">  281</span>&#160;<span class="comment">  /**</span></div><div class="line"><a name="l00282"></a><span class="lineno">  282</span>&#160;<span class="comment">   * Appends a layer that performs softmax normalization (along channel axis).</span></div><div class="line"><a name="l00283"></a><span class="lineno">  283</span>&#160;<span class="comment">   *</span></div><div class="line"><a name="l00284"></a><span class="lineno">  284</span>&#160;<span class="comment">   * \param name The name of the layer and its output</span></div><div class="line"><a name="l00285"></a><span class="lineno">  285</span>&#160;<span class="comment">   * \param input The name of the layer&#39;s input</span></div><div class="line"><a name="l00286"></a><span class="lineno">  286</span>&#160;<span class="comment">   */</span></div><div class="line"><a name="l00287"></a><span class="lineno">  287</span>&#160;  <span class="keywordtype">void</span> add_softmax(<span class="keyword">const</span> std::string&amp; name, <span class="keyword">const</span> std::string&amp; input);</div><div class="line"><a name="l00288"></a><span class="lineno">  288</span>&#160;<span class="comment"></span></div><div class="line"><a name="l00289"></a><span class="lineno">  289</span>&#160;<span class="comment">  /**</span></div><div class="line"><a name="l00290"></a><span class="lineno">  290</span>&#160;<span class="comment">   * Appends a layer that performs flatten normalization (along channel axis).</span></div><div class="line"><a name="l00291"></a><span class="lineno">  291</span>&#160;<span class="comment">   *</span></div><div class="line"><a name="l00292"></a><span class="lineno">  292</span>&#160;<span class="comment">   * currently only supports channel first flattening, which means if the input order is</span></div><div class="line"><a name="l00293"></a><span class="lineno">  293</span>&#160;<span class="comment">   * ``[C, H, W]``, then output array will be ``[C * H * W, 1, 1]``, still `C-major`</span></div><div class="line"><a name="l00294"></a><span class="lineno">  294</span>&#160;<span class="comment">   * orderring. No underlying array storage will be changed.</span></div><div class="line"><a name="l00295"></a><span class="lineno">  295</span>&#160;<span class="comment">   *</span></div><div class="line"><a name="l00296"></a><span class="lineno">  296</span>&#160;<span class="comment">   * \param name The name of the layer and its output</span></div><div class="line"><a name="l00297"></a><span class="lineno">  297</span>&#160;<span class="comment">   * \param input The name of the layer&#39;s input</span></div><div class="line"><a name="l00298"></a><span class="lineno">  298</span>&#160;<span class="comment">   */</span></div><div class="line"><a name="l00299"></a><span class="lineno">  299</span>&#160;  <span class="keywordtype">void</span> add_flatten(<span class="keyword">const</span> std::string&amp; name, <span class="keyword">const</span> std::string&amp; input);</div><div class="line"><a name="l00300"></a><span class="lineno">  300</span>&#160;<span class="comment"></span></div><div class="line"><a name="l00301"></a><span class="lineno">  301</span>&#160;<span class="comment">  /**</span></div><div class="line"><a name="l00302"></a><span class="lineno">  302</span>&#160;<span class="comment">   * Appends a layer that performs elementwise addition.</span></div><div class="line"><a name="l00303"></a><span class="lineno">  303</span>&#160;<span class="comment">   *</span></div><div class="line"><a name="l00304"></a><span class="lineno">  304</span>&#160;<span class="comment">   * \param name The name of the layer and its output</span></div><div class="line"><a name="l00305"></a><span class="lineno">  305</span>&#160;<span class="comment">   * \param inputs The names of the layer&#39;s inputs</span></div><div class="line"><a name="l00306"></a><span class="lineno">  306</span>&#160;<span class="comment">   */</span></div><div class="line"><a name="l00307"></a><span class="lineno">  307</span>&#160;  <span class="keywordtype">void</span> add_addition(<span class="keyword">const</span> std::string&amp; name,</div><div class="line"><a name="l00308"></a><span class="lineno">  308</span>&#160;                    <span class="keyword">const</span> std::vector&lt;std::string&gt;&amp; inputs);</div><div class="line"><a name="l00309"></a><span class="lineno">  309</span>&#160;<span class="comment"></span></div><div class="line"><a name="l00310"></a><span class="lineno">  310</span>&#160;<span class="comment">  /**</span></div><div class="line"><a name="l00311"></a><span class="lineno">  311</span>&#160;<span class="comment">   * Appends a layer that performs elementwise multiplication.</span></div><div class="line"><a name="l00312"></a><span class="lineno">  312</span>&#160;<span class="comment">   *</span></div><div class="line"><a name="l00313"></a><span class="lineno">  313</span>&#160;<span class="comment">   * \param name The name of the layer and its output</span></div><div class="line"><a name="l00314"></a><span class="lineno">  314</span>&#160;<span class="comment">   * \param inputs The names of the layer&#39;s inputs</span></div><div class="line"><a name="l00315"></a><span class="lineno">  315</span>&#160;<span class="comment">   */</span></div><div class="line"><a name="l00316"></a><span class="lineno">  316</span>&#160;  <span class="keywordtype">void</span> add_multiplication(<span class="keyword">const</span> std::string&amp; name,</div><div class="line"><a name="l00317"></a><span class="lineno">  317</span>&#160;                          <span class="keyword">const</span> std::vector&lt;std::string&gt;&amp; inputs);</div><div class="line"><a name="l00318"></a><span class="lineno">  318</span>&#160;<span class="comment"></span></div><div class="line"><a name="l00319"></a><span class="lineno">  319</span>&#160;<span class="comment">  /**</span></div><div class="line"><a name="l00320"></a><span class="lineno">  320</span>&#160;<span class="comment">   * Appends a layer that applies the unary function f(x) = e^x to its input.</span></div><div class="line"><a name="l00321"></a><span class="lineno">  321</span>&#160;<span class="comment">   *</span></div><div class="line"><a name="l00322"></a><span class="lineno">  322</span>&#160;<span class="comment">   * \param name The name of the layer and its output</span></div><div class="line"><a name="l00323"></a><span class="lineno">  323</span>&#160;<span class="comment">   * \param input The name of the layer&#39;s input</span></div><div class="line"><a name="l00324"></a><span class="lineno">  324</span>&#160;<span class="comment">   */</span></div><div class="line"><a name="l00325"></a><span class="lineno">  325</span>&#160;  <span class="keywordtype">void</span> add_exp(<span class="keyword">const</span> std::string&amp; name, <span class="keyword">const</span> std::string&amp; input);</div><div class="line"><a name="l00326"></a><span class="lineno">  326</span>&#160;</div><div class="line"><a name="l00327"></a><span class="lineno">  327</span>&#160;<span class="comment"></span></div><div class="line"><a name="l00328"></a><span class="lineno">  328</span>&#160;<span class="comment">  /**</span></div><div class="line"><a name="l00329"></a><span class="lineno">  329</span>&#160;<span class="comment">   * Appends a layer that performs elementwise multiplication between its input</span></div><div class="line"><a name="l00330"></a><span class="lineno">  330</span>&#160;<span class="comment">   * and some fixed weights.</span></div><div class="line"><a name="l00331"></a><span class="lineno">  331</span>&#160;<span class="comment">   *</span></div><div class="line"><a name="l00332"></a><span class="lineno">  332</span>&#160;<span class="comment">   * \param name The name of the layer and its output</span></div><div class="line"><a name="l00333"></a><span class="lineno">  333</span>&#160;<span class="comment">   * \param input The name of the layer&#39;s input</span></div><div class="line"><a name="l00334"></a><span class="lineno">  334</span>&#160;<span class="comment">   * \param shape_c_h_w The shape of the input and output</span></div><div class="line"><a name="l00335"></a><span class="lineno">  335</span>&#160;<span class="comment">   * \param weight_initializer_fn Callback used to initialize the weights</span></div><div class="line"><a name="l00336"></a><span class="lineno">  336</span>&#160;<span class="comment">   */</span></div><div class="line"><a name="l00337"></a><span class="lineno">  337</span>&#160;  <span class="keywordtype">void</span> add_scale(<span class="keyword">const</span> std::string&amp; name, <span class="keyword">const</span> std::string&amp; input,</div><div class="line"><a name="l00338"></a><span class="lineno">  338</span>&#160;                 <span class="keyword">const</span> std::vector&lt;size_t&gt;&amp; shape_c_h_w,</div><div class="line"><a name="l00339"></a><span class="lineno">  339</span>&#160;                 weight_initializer scale_initializer_fn);</div><div class="line"><a name="l00340"></a><span class="lineno">  340</span>&#160;<span class="comment"></span></div><div class="line"><a name="l00341"></a><span class="lineno">  341</span>&#160;<span class="comment">  /**</span></div><div class="line"><a name="l00342"></a><span class="lineno">  342</span>&#160;<span class="comment">   * Appends a layer with fixed values.</span></div><div class="line"><a name="l00343"></a><span class="lineno">  343</span>&#160;<span class="comment">   *</span></div><div class="line"><a name="l00344"></a><span class="lineno">  344</span>&#160;<span class="comment">   * \param name The name of the layer and its output</span></div><div class="line"><a name="l00345"></a><span class="lineno">  345</span>&#160;<span class="comment">   * \param shape_c_h_w The shape of the output</span></div><div class="line"><a name="l00346"></a><span class="lineno">  346</span>&#160;<span class="comment">   * \param weight_initializer_fn Callback used to initialize the weights</span></div><div class="line"><a name="l00347"></a><span class="lineno">  347</span>&#160;<span class="comment">   */</span></div><div class="line"><a name="l00348"></a><span class="lineno">  348</span>&#160;  <span class="keywordtype">void</span> add_constant(<span class="keyword">const</span> std::string&amp; name,</div><div class="line"><a name="l00349"></a><span class="lineno">  349</span>&#160;                    <span class="keyword">const</span> std::array&lt;size_t, 3&gt;&amp; shape_c_h_w,</div><div class="line"><a name="l00350"></a><span class="lineno">  350</span>&#160;                    weight_initializer weight_initializer_fn);</div><div class="line"><a name="l00351"></a><span class="lineno">  351</span>&#160;<span class="comment"></span></div><div class="line"><a name="l00352"></a><span class="lineno">  352</span>&#160;<span class="comment">  /**</span></div><div class="line"><a name="l00353"></a><span class="lineno">  353</span>&#160;<span class="comment">   * Appends a layer that reshapes its input.</span></div><div class="line"><a name="l00354"></a><span class="lineno">  354</span>&#160;<span class="comment">   *</span></div><div class="line"><a name="l00355"></a><span class="lineno">  355</span>&#160;<span class="comment">   * \param name The name of the layer and its output</span></div><div class="line"><a name="l00356"></a><span class="lineno">  356</span>&#160;<span class="comment">   * \param input The name of the layer&#39;s input</span></div><div class="line"><a name="l00357"></a><span class="lineno">  357</span>&#160;<span class="comment">   * \param shape_c_h_w The shape of the output</span></div><div class="line"><a name="l00358"></a><span class="lineno">  358</span>&#160;<span class="comment">   */</span></div><div class="line"><a name="l00359"></a><span class="lineno">  359</span>&#160;  <span class="keywordtype">void</span> add_reshape(<span class="keyword">const</span> std::string&amp; name, <span class="keyword">const</span> std::string&amp; input,</div><div class="line"><a name="l00360"></a><span class="lineno">  360</span>&#160;                   <span class="keyword">const</span> std::array&lt;size_t, 4&gt;&amp; seq_c_h_w);</div><div class="line"><a name="l00361"></a><span class="lineno">  361</span>&#160;<span class="comment"></span></div><div class="line"><a name="l00362"></a><span class="lineno">  362</span>&#160;<span class="comment">  /**</span></div><div class="line"><a name="l00363"></a><span class="lineno">  363</span>&#160;<span class="comment">   * Appends a layer that transposes the dimensions of its input</span></div><div class="line"><a name="l00364"></a><span class="lineno">  364</span>&#160;<span class="comment">   *</span></div><div class="line"><a name="l00365"></a><span class="lineno">  365</span>&#160;<span class="comment">   * \param name The name of the layer and its output</span></div><div class="line"><a name="l00366"></a><span class="lineno">  366</span>&#160;<span class="comment">   * \param input The name of the layer&#39;s input</span></div><div class="line"><a name="l00367"></a><span class="lineno">  367</span>&#160;<span class="comment">   * \param axis_permutation A permutation of [0, 1, 2, 3], describing how to</span></div><div class="line"><a name="l00368"></a><span class="lineno">  368</span>&#160;<span class="comment">   *            rearrange the [Seq, C, H, W] input.</span></div><div class="line"><a name="l00369"></a><span class="lineno">  369</span>&#160;<span class="comment">   */</span></div><div class="line"><a name="l00370"></a><span class="lineno">  370</span>&#160;  <span class="keywordtype">void</span> add_permute(<span class="keyword">const</span> std::string&amp; name, <span class="keyword">const</span> std::string&amp; input,</div><div class="line"><a name="l00371"></a><span class="lineno">  371</span>&#160;                   <span class="keyword">const</span> std::array&lt;size_t, 4&gt;&amp; axis_permutation);</div><div class="line"><a name="l00372"></a><span class="lineno">  372</span>&#160;<span class="comment"></span></div><div class="line"><a name="l00373"></a><span class="lineno">  373</span>&#160;<span class="comment">  /**</span></div><div class="line"><a name="l00374"></a><span class="lineno">  374</span>&#160;<span class="comment">   * Appends a layer that slices the input along the channel axis.</span></div><div class="line"><a name="l00375"></a><span class="lineno">  375</span>&#160;<span class="comment">   *</span></div><div class="line"><a name="l00376"></a><span class="lineno">  376</span>&#160;<span class="comment">   * \param name The name of the layer and its output</span></div><div class="line"><a name="l00377"></a><span class="lineno">  377</span>&#160;<span class="comment">   * \param input The name of the layer&#39;s input</span></div><div class="line"><a name="l00378"></a><span class="lineno">  378</span>&#160;<span class="comment">   * \param start_index The first channel to include</span></div><div class="line"><a name="l00379"></a><span class="lineno">  379</span>&#160;<span class="comment">   * \param end_index The first channel to stop including. If negative, then the</span></div><div class="line"><a name="l00380"></a><span class="lineno">  380</span>&#160;<span class="comment">   *            number of channels is added first (so -1 becomes n - 1).</span></div><div class="line"><a name="l00381"></a><span class="lineno">  381</span>&#160;<span class="comment">   * \param stride The interval between channels to include</span></div><div class="line"><a name="l00382"></a><span class="lineno">  382</span>&#160;<span class="comment">   */</span></div><div class="line"><a name="l00383"></a><span class="lineno">  383</span>&#160;  <span class="keywordtype">void</span> add_channel_slice(<span class="keyword">const</span> std::string&amp; name, <span class="keyword">const</span> std::string&amp; input,</div><div class="line"><a name="l00384"></a><span class="lineno">  384</span>&#160;                         <span class="keywordtype">int</span> start_index, <span class="keywordtype">int</span> end_index, <span class="keywordtype">size_t</span> stride);</div><div class="line"><a name="l00385"></a><span class="lineno">  385</span>&#160;<span class="comment"></span></div><div class="line"><a name="l00386"></a><span class="lineno">  386</span>&#160;<span class="comment">  /**</span></div><div class="line"><a name="l00387"></a><span class="lineno">  387</span>&#160;<span class="comment">   * Appends an LSTM layer.</span></div><div class="line"><a name="l00388"></a><span class="lineno">  388</span>&#160;<span class="comment">   *</span></div><div class="line"><a name="l00389"></a><span class="lineno">  389</span>&#160;<span class="comment">   * \param name The name of the layer and its output</span></div><div class="line"><a name="l00390"></a><span class="lineno">  390</span>&#160;<span class="comment">   * \param input The name of the layer&#39;s input</span></div><div class="line"><a name="l00391"></a><span class="lineno">  391</span>&#160;<span class="comment">   * \param hidden_input The name of the initial hidden state</span></div><div class="line"><a name="l00392"></a><span class="lineno">  392</span>&#160;<span class="comment">   * \param cell_input The name of the initial cell state</span></div><div class="line"><a name="l00393"></a><span class="lineno">  393</span>&#160;<span class="comment">   * \param hidden_output The name of the resulting hidden state</span></div><div class="line"><a name="l00394"></a><span class="lineno">  394</span>&#160;<span class="comment">   * \param cell_output The name of the resulting cell state</span></div><div class="line"><a name="l00395"></a><span class="lineno">  395</span>&#160;<span class="comment">   * \param input_vector_size The size of the input vector</span></div><div class="line"><a name="l00396"></a><span class="lineno">  396</span>&#160;<span class="comment">   * \param output_vector_size The size of the output vector (hidden state and</span></div><div class="line"><a name="l00397"></a><span class="lineno">  397</span>&#160;<span class="comment">   *            cell state)</span></div><div class="line"><a name="l00398"></a><span class="lineno">  398</span>&#160;<span class="comment">   * \param cell_clip_threshold Maximum magnitude of cell state values</span></div><div class="line"><a name="l00399"></a><span class="lineno">  399</span>&#160;<span class="comment">   * \param initializers LSTM weights</span></div><div class="line"><a name="l00400"></a><span class="lineno">  400</span>&#160;<span class="comment">   */</span></div><div class="line"><a name="l00401"></a><span class="lineno">  401</span>&#160;  <span class="keywordtype">void</span> add_lstm(<span class="keyword">const</span> std::string&amp; name, <span class="keyword">const</span> std::string&amp; input,</div><div class="line"><a name="l00402"></a><span class="lineno">  402</span>&#160;                <span class="keyword">const</span> std::string&amp; hidden_input, <span class="keyword">const</span> std::string&amp; cell_input,</div><div class="line"><a name="l00403"></a><span class="lineno">  403</span>&#160;                <span class="keyword">const</span> std::string&amp; hidden_output,</div><div class="line"><a name="l00404"></a><span class="lineno">  404</span>&#160;                <span class="keyword">const</span> std::string&amp; cell_output, <span class="keywordtype">size_t</span> input_vector_size,</div><div class="line"><a name="l00405"></a><span class="lineno">  405</span>&#160;                <span class="keywordtype">size_t</span> output_vector_size, <span class="keywordtype">float</span> cell_clip_threshold,</div><div class="line"><a name="l00406"></a><span class="lineno">  406</span>&#160;                <span class="keyword">const</span> <a class="code" href="structturi_1_1neural__net_1_1lstm__weight__initializers.html">lstm_weight_initializers</a>&amp; initializers);</div><div class="line"><a name="l00407"></a><span class="lineno">  407</span>&#160;</div><div class="line"><a name="l00408"></a><span class="lineno">  408</span>&#160;  <span class="comment">// TODO: Support additional layers (and further parameterize the above) as</span></div><div class="line"><a name="l00409"></a><span class="lineno">  409</span>&#160;  <span class="comment">// needed. If/when we support the full range of NeuralNetworkLayer values,</span></div><div class="line"><a name="l00410"></a><span class="lineno">  410</span>&#160;  <span class="comment">// this could be shared in some form with coremltools.</span></div><div class="line"><a name="l00411"></a><span class="lineno">  411</span>&#160;<span class="comment"></span></div><div class="line"><a name="l00412"></a><span class="lineno">  412</span>&#160;<span class="comment">  /**</span></div><div class="line"><a name="l00413"></a><span class="lineno">  413</span>&#160;<span class="comment">   * Appends a preprocessing layer</span></div><div class="line"><a name="l00414"></a><span class="lineno">  414</span>&#160;<span class="comment">   * Now only support image scaling preprocessing though.</span></div><div class="line"><a name="l00415"></a><span class="lineno">  415</span>&#160;<span class="comment">   */</span></div><div class="line"><a name="l00416"></a><span class="lineno">  416</span>&#160;  <span class="keywordtype">void</span> add_preprocessing(<span class="keyword">const</span> std::string&amp; feature_name,</div><div class="line"><a name="l00417"></a><span class="lineno">  417</span>&#160;                         <span class="keyword">const</span> <span class="keywordtype">float</span> image_scale);</div><div class="line"><a name="l00418"></a><span class="lineno">  418</span>&#160;<span class="comment"></span></div><div class="line"><a name="l00419"></a><span class="lineno">  419</span>&#160;<span class="comment">  /**</span></div><div class="line"><a name="l00420"></a><span class="lineno">  420</span>&#160;<span class="comment">   * Appends an Transpose layer.</span></div><div class="line"><a name="l00421"></a><span class="lineno">  421</span>&#160;<span class="comment">   *</span></div><div class="line"><a name="l00422"></a><span class="lineno">  422</span>&#160;<span class="comment">   * \param name The name of the layer and its output</span></div><div class="line"><a name="l00423"></a><span class="lineno">  423</span>&#160;<span class="comment">   * \param input The name of the layer&#39;s input</span></div><div class="line"><a name="l00424"></a><span class="lineno">  424</span>&#160;<span class="comment">   * \param axes The ordering of the axes to transpose for instance {0, 2, 1, 3}</span></div><div class="line"><a name="l00425"></a><span class="lineno">  425</span>&#160;<span class="comment">   *             would flip the channel and height axes</span></div><div class="line"><a name="l00426"></a><span class="lineno">  426</span>&#160;<span class="comment">   */</span></div><div class="line"><a name="l00427"></a><span class="lineno">  427</span>&#160;  <span class="keywordtype">void</span> add_transpose(<span class="keyword">const</span> std::string&amp; name, <span class="keyword">const</span> std::string&amp; input,</div><div class="line"><a name="l00428"></a><span class="lineno">  428</span>&#160;                     std::vector&lt;size_t&gt; axes);</div><div class="line"><a name="l00429"></a><span class="lineno">  429</span>&#160;<span class="comment"></span></div><div class="line"><a name="l00430"></a><span class="lineno">  430</span>&#160;<span class="comment">  /**</span></div><div class="line"><a name="l00431"></a><span class="lineno">  431</span>&#160;<span class="comment">   * Appends an Split layer.</span></div><div class="line"><a name="l00432"></a><span class="lineno">  432</span>&#160;<span class="comment">   *</span></div><div class="line"><a name="l00433"></a><span class="lineno">  433</span>&#160;<span class="comment">   * \param name The name of the layer and its output</span></div><div class="line"><a name="l00434"></a><span class="lineno">  434</span>&#160;<span class="comment">   * \param input The name of the layer&#39;s input</span></div><div class="line"><a name="l00435"></a><span class="lineno">  435</span>&#160;<span class="comment">   * \param axis The axis to split the layer on</span></div><div class="line"><a name="l00436"></a><span class="lineno">  436</span>&#160;<span class="comment">   * \param num_splits The number of splits to perform</span></div><div class="line"><a name="l00437"></a><span class="lineno">  437</span>&#160;<span class="comment">   * \param split_sizes The size of each split</span></div><div class="line"><a name="l00438"></a><span class="lineno">  438</span>&#160;<span class="comment">   */</span></div><div class="line"><a name="l00439"></a><span class="lineno">  439</span>&#160;  <span class="keywordtype">void</span> add_split_nd(<span class="keyword">const</span> std::string&amp; name, <span class="keyword">const</span> std::string&amp; input,</div><div class="line"><a name="l00440"></a><span class="lineno">  440</span>&#160;                    <span class="keywordtype">size_t</span> axis, <span class="keywordtype">size_t</span> num_splits,</div><div class="line"><a name="l00441"></a><span class="lineno">  441</span>&#160;                    <span class="keyword">const</span> std::vector&lt;size_t&gt;&amp; split_sizes);</div><div class="line"><a name="l00442"></a><span class="lineno">  442</span>&#160;<span class="comment"></span></div><div class="line"><a name="l00443"></a><span class="lineno">  443</span>&#160;<span class="comment">  /**</span></div><div class="line"><a name="l00444"></a><span class="lineno">  444</span>&#160;<span class="comment">   * Appends an Concat layer.</span></div><div class="line"><a name="l00445"></a><span class="lineno">  445</span>&#160;<span class="comment">   *</span></div><div class="line"><a name="l00446"></a><span class="lineno">  446</span>&#160;<span class="comment">   * \param name The name of the layer and its output</span></div><div class="line"><a name="l00447"></a><span class="lineno">  447</span>&#160;<span class="comment">   * \param inputs The vector of names of the layer&#39;s inputs</span></div><div class="line"><a name="l00448"></a><span class="lineno">  448</span>&#160;<span class="comment">   * \param axis The axis to concat the layer on</span></div><div class="line"><a name="l00449"></a><span class="lineno">  449</span>&#160;<span class="comment">   */</span></div><div class="line"><a name="l00450"></a><span class="lineno">  450</span>&#160;  <span class="keywordtype">void</span> add_concat_nd(<span class="keyword">const</span> std::string&amp; name,</div><div class="line"><a name="l00451"></a><span class="lineno">  451</span>&#160;                     <span class="keyword">const</span> std::vector&lt;std::string&gt;&amp; inputs, <span class="keywordtype">size_t</span> axis);</div><div class="line"><a name="l00452"></a><span class="lineno">  452</span>&#160;<span class="comment"></span></div><div class="line"><a name="l00453"></a><span class="lineno">  453</span>&#160;<span class="comment">  /**</span></div><div class="line"><a name="l00454"></a><span class="lineno">  454</span>&#160;<span class="comment">   * Appends a Reshape Static layer.</span></div><div class="line"><a name="l00455"></a><span class="lineno">  455</span>&#160;<span class="comment">   *</span></div><div class="line"><a name="l00456"></a><span class="lineno">  456</span>&#160;<span class="comment">   * \param name The name of the layer and its output</span></div><div class="line"><a name="l00457"></a><span class="lineno">  457</span>&#160;<span class="comment">   * \param input The vector of names of the layer&#39;s input</span></div><div class="line"><a name="l00458"></a><span class="lineno">  458</span>&#160;<span class="comment">   * \param targetShape The target shape</span></div><div class="line"><a name="l00459"></a><span class="lineno">  459</span>&#160;<span class="comment">   */</span></div><div class="line"><a name="l00460"></a><span class="lineno">  460</span>&#160;  <span class="keywordtype">void</span> add_reshape_static(<span class="keyword">const</span> std::string&amp; name, <span class="keyword">const</span> std::string&amp; input,</div><div class="line"><a name="l00461"></a><span class="lineno">  461</span>&#160;                          <span class="keyword">const</span> std::vector&lt;size_t&gt;&amp; targetShape);</div><div class="line"><a name="l00462"></a><span class="lineno">  462</span>&#160;<span class="comment"></span></div><div class="line"><a name="l00463"></a><span class="lineno">  463</span>&#160;<span class="comment">  /**</span></div><div class="line"><a name="l00464"></a><span class="lineno">  464</span>&#160;<span class="comment">   * Appends a Reshape Dynamic layer.</span></div><div class="line"><a name="l00465"></a><span class="lineno">  465</span>&#160;<span class="comment">   *</span></div><div class="line"><a name="l00466"></a><span class="lineno">  466</span>&#160;<span class="comment">   * \param name The name of the layer and its output</span></div><div class="line"><a name="l00467"></a><span class="lineno">  467</span>&#160;<span class="comment">   * \param inputs The vector of names of the layer&#39;s inputs</span></div><div class="line"><a name="l00468"></a><span class="lineno">  468</span>&#160;<span class="comment">   */</span></div><div class="line"><a name="l00469"></a><span class="lineno">  469</span>&#160;  <span class="keywordtype">void</span> add_reshape_dynamic(<span class="keyword">const</span> std::string&amp; name,</div><div class="line"><a name="l00470"></a><span class="lineno">  470</span>&#160;                           <span class="keyword">const</span> std::vector&lt;std::string&gt;&amp; inputs);</div><div class="line"><a name="l00471"></a><span class="lineno">  471</span>&#160;<span class="comment"></span></div><div class="line"><a name="l00472"></a><span class="lineno">  472</span>&#160;<span class="comment">  /**</span></div><div class="line"><a name="l00473"></a><span class="lineno">  473</span>&#160;<span class="comment">   * Appends an Expand Dims layer.</span></div><div class="line"><a name="l00474"></a><span class="lineno">  474</span>&#160;<span class="comment">   *</span></div><div class="line"><a name="l00475"></a><span class="lineno">  475</span>&#160;<span class="comment">   * \param name The name of the layer and its output</span></div><div class="line"><a name="l00476"></a><span class="lineno">  476</span>&#160;<span class="comment">   * \param input The vector of names of the layer&#39;s input</span></div><div class="line"><a name="l00477"></a><span class="lineno">  477</span>&#160;<span class="comment">   * \param axes The axes to expand the layer on</span></div><div class="line"><a name="l00478"></a><span class="lineno">  478</span>&#160;<span class="comment">   */</span></div><div class="line"><a name="l00479"></a><span class="lineno">  479</span>&#160;  <span class="keywordtype">void</span> add_expand_dims(<span class="keyword">const</span> std::string&amp; name, <span class="keyword">const</span> std::string&amp; input,</div><div class="line"><a name="l00480"></a><span class="lineno">  480</span>&#160;                       <span class="keyword">const</span> std::vector&lt;size_t&gt;&amp; axes,</div><div class="line"><a name="l00481"></a><span class="lineno">  481</span>&#160;                       <span class="keyword">const</span> std::vector&lt;size_t&gt;&amp; inputVector,</div><div class="line"><a name="l00482"></a><span class="lineno">  482</span>&#160;                       <span class="keyword">const</span> std::vector&lt;size_t&gt;&amp; outputVector);</div><div class="line"><a name="l00483"></a><span class="lineno">  483</span>&#160;<span class="comment"></span></div><div class="line"><a name="l00484"></a><span class="lineno">  484</span>&#160;<span class="comment">  /**</span></div><div class="line"><a name="l00485"></a><span class="lineno">  485</span>&#160;<span class="comment">   * Appends a Squeeze layer.</span></div><div class="line"><a name="l00486"></a><span class="lineno">  486</span>&#160;<span class="comment">   *</span></div><div class="line"><a name="l00487"></a><span class="lineno">  487</span>&#160;<span class="comment">   * \param name The name of the layer and its output</span></div><div class="line"><a name="l00488"></a><span class="lineno">  488</span>&#160;<span class="comment">   * \param input The vector of names of the layer&#39;s input</span></div><div class="line"><a name="l00489"></a><span class="lineno">  489</span>&#160;<span class="comment">   * \param axes The axes to squeeze the layer on</span></div><div class="line"><a name="l00490"></a><span class="lineno">  490</span>&#160;<span class="comment">   */</span></div><div class="line"><a name="l00491"></a><span class="lineno">  491</span>&#160;  <span class="keywordtype">void</span> add_squeeze(<span class="keyword">const</span> std::string&amp; name, <span class="keyword">const</span> std::string&amp; input,</div><div class="line"><a name="l00492"></a><span class="lineno">  492</span>&#160;                   <span class="keyword">const</span> std::vector&lt;size_t&gt;&amp; axes,</div><div class="line"><a name="l00493"></a><span class="lineno">  493</span>&#160;                   <span class="keyword">const</span> std::vector&lt;size_t&gt;&amp; inputVector,</div><div class="line"><a name="l00494"></a><span class="lineno">  494</span>&#160;                   <span class="keyword">const</span> std::vector&lt;size_t&gt;&amp; outputVector);</div><div class="line"><a name="l00495"></a><span class="lineno">  495</span>&#160;<span class="comment"></span></div><div class="line"><a name="l00496"></a><span class="lineno">  496</span>&#160;<span class="comment">  /**</span></div><div class="line"><a name="l00497"></a><span class="lineno">  497</span>&#160;<span class="comment">   * Appends an Add Broadcastable layer.</span></div><div class="line"><a name="l00498"></a><span class="lineno">  498</span>&#160;<span class="comment">   *</span></div><div class="line"><a name="l00499"></a><span class="lineno">  499</span>&#160;<span class="comment">   * \param name The name of the layer and its output</span></div><div class="line"><a name="l00500"></a><span class="lineno">  500</span>&#160;<span class="comment">   * \param inputs The vector of names of the layer&#39;s inputs</span></div><div class="line"><a name="l00501"></a><span class="lineno">  501</span>&#160;<span class="comment">   */</span></div><div class="line"><a name="l00502"></a><span class="lineno">  502</span>&#160;  <span class="keywordtype">void</span> add_add_broadcastable(<span class="keyword">const</span> std::string&amp; name,</div><div class="line"><a name="l00503"></a><span class="lineno">  503</span>&#160;                             <span class="keyword">const</span> std::vector&lt;std::string&gt;&amp; inputs);</div><div class="line"><a name="l00504"></a><span class="lineno">  504</span>&#160;<span class="comment"></span></div><div class="line"><a name="l00505"></a><span class="lineno">  505</span>&#160;<span class="comment">  /**</span></div><div class="line"><a name="l00506"></a><span class="lineno">  506</span>&#160;<span class="comment">   * Appends a Gather layer.</span></div><div class="line"><a name="l00507"></a><span class="lineno">  507</span>&#160;<span class="comment">   *</span></div><div class="line"><a name="l00508"></a><span class="lineno">  508</span>&#160;<span class="comment">   * \param name The name of the layer and its output</span></div><div class="line"><a name="l00509"></a><span class="lineno">  509</span>&#160;<span class="comment">   * \param inputs The vector of names of the layer&#39;s inputs</span></div><div class="line"><a name="l00510"></a><span class="lineno">  510</span>&#160;<span class="comment">   */</span></div><div class="line"><a name="l00511"></a><span class="lineno">  511</span>&#160;  <span class="keywordtype">void</span> add_gather(<span class="keyword">const</span> std::string&amp; name,</div><div class="line"><a name="l00512"></a><span class="lineno">  512</span>&#160;                  <span class="keyword">const</span> std::vector&lt;std::string&gt;&amp; inputs);</div><div class="line"><a name="l00513"></a><span class="lineno">  513</span>&#160;<span class="comment"></span></div><div class="line"><a name="l00514"></a><span class="lineno">  514</span>&#160;<span class="comment">  /**</span></div><div class="line"><a name="l00515"></a><span class="lineno">  515</span>&#160;<span class="comment">   * Appends a Constant ND layer.</span></div><div class="line"><a name="l00516"></a><span class="lineno">  516</span>&#160;<span class="comment">   *</span></div><div class="line"><a name="l00517"></a><span class="lineno">  517</span>&#160;<span class="comment">   * \param name The name of the layer and its output</span></div><div class="line"><a name="l00518"></a><span class="lineno">  518</span>&#160;<span class="comment">   * \param shape The shape of the constant layer</span></div><div class="line"><a name="l00519"></a><span class="lineno">  519</span>&#160;<span class="comment">   * \param data The data being loaded in the constant layer</span></div><div class="line"><a name="l00520"></a><span class="lineno">  520</span>&#160;<span class="comment">   */</span></div><div class="line"><a name="l00521"></a><span class="lineno">  521</span>&#160;  <span class="keywordtype">void</span> add_constant_nd(<span class="keyword">const</span> std::string&amp; name,</div><div class="line"><a name="l00522"></a><span class="lineno">  522</span>&#160;                       <span class="keyword">const</span> std::vector&lt;size_t&gt;&amp; shape,</div><div class="line"><a name="l00523"></a><span class="lineno">  523</span>&#160;                       <span class="keyword">const</span> weight_initializer&amp; data);</div><div class="line"><a name="l00524"></a><span class="lineno">  524</span>&#160;<span class="comment"></span></div><div class="line"><a name="l00525"></a><span class="lineno">  525</span>&#160;<span class="comment">  /**</span></div><div class="line"><a name="l00526"></a><span class="lineno">  526</span>&#160;<span class="comment">   * Appends a Get Shape layer.</span></div><div class="line"><a name="l00527"></a><span class="lineno">  527</span>&#160;<span class="comment">   *</span></div><div class="line"><a name="l00528"></a><span class="lineno">  528</span>&#160;<span class="comment">   * \param name The name of the layer and its output</span></div><div class="line"><a name="l00529"></a><span class="lineno">  529</span>&#160;<span class="comment">   * \param input The vector of names of the layer&#39;s input</span></div><div class="line"><a name="l00530"></a><span class="lineno">  530</span>&#160;<span class="comment">   */</span></div><div class="line"><a name="l00531"></a><span class="lineno">  531</span>&#160;  <span class="keywordtype">void</span> add_get_shape(<span class="keyword">const</span> std::string&amp; name, <span class="keyword">const</span> std::string&amp; input);</div><div class="line"><a name="l00532"></a><span class="lineno">  532</span>&#160;<span class="comment"></span></div><div class="line"><a name="l00533"></a><span class="lineno">  533</span>&#160;<span class="comment">  /**</span></div><div class="line"><a name="l00534"></a><span class="lineno">  534</span>&#160;<span class="comment">   * Appends dynamic slicing.</span></div><div class="line"><a name="l00535"></a><span class="lineno">  535</span>&#160;<span class="comment">   *</span></div><div class="line"><a name="l00536"></a><span class="lineno">  536</span>&#160;<span class="comment">   * \param name The name of the layer and its output</span></div><div class="line"><a name="l00537"></a><span class="lineno">  537</span>&#160;<span class="comment">   * \param inputs The name of the layer&#39;s inputs</span></div><div class="line"><a name="l00538"></a><span class="lineno">  538</span>&#160;<span class="comment">   */</span></div><div class="line"><a name="l00539"></a><span class="lineno">  539</span>&#160;  <span class="keywordtype">void</span> add_slice_dynamic(<span class="keyword">const</span> std::string&amp; name, <span class="keyword">const</span> std::vector&lt;std::string&gt;&amp; inputs);</div><div class="line"><a name="l00540"></a><span class="lineno">  540</span>&#160;<span class="comment"></span></div><div class="line"><a name="l00541"></a><span class="lineno">  541</span>&#160;<span class="comment">  /**</span></div><div class="line"><a name="l00542"></a><span class="lineno">  542</span>&#160;<span class="comment">   * Appends a non maximum suppression  layer.</span></div><div class="line"><a name="l00543"></a><span class="lineno">  543</span>&#160;<span class="comment">   *</span></div><div class="line"><a name="l00544"></a><span class="lineno">  544</span>&#160;<span class="comment">   * \param name The name of the layer and its output</span></div><div class="line"><a name="l00545"></a><span class="lineno">  545</span>&#160;<span class="comment">   * \param inputs The name of the layer&#39;s inputs</span></div><div class="line"><a name="l00546"></a><span class="lineno">  546</span>&#160;<span class="comment">   * \param outputs The outputs of the layer</span></div><div class="line"><a name="l00547"></a><span class="lineno">  547</span>&#160;<span class="comment">   * \param iou_thrsshold The default value for the iou threshold</span></div><div class="line"><a name="l00548"></a><span class="lineno">  548</span>&#160;<span class="comment">   * \param confidence_threshold The default value for the confidence threshold</span></div><div class="line"><a name="l00549"></a><span class="lineno">  549</span>&#160;<span class="comment">   * \param max_boxes The maximum number of boxes you want NMS to run</span></div><div class="line"><a name="l00550"></a><span class="lineno">  550</span>&#160;<span class="comment">   * \param per_class_suppression When false, suppression happens for all</span></div><div class="line"><a name="l00551"></a><span class="lineno">  551</span>&#160;<span class="comment">   * classes.</span></div><div class="line"><a name="l00552"></a><span class="lineno">  552</span>&#160;<span class="comment">   */</span></div><div class="line"><a name="l00553"></a><span class="lineno">  553</span>&#160;  <span class="keywordtype">void</span> add_nms_layer(<span class="keyword">const</span> std::string&amp; name, <span class="keyword">const</span> std::vector&lt;std::string&gt;&amp; inputs,</div><div class="line"><a name="l00554"></a><span class="lineno">  554</span>&#160;                     <span class="keyword">const</span> std::vector&lt;std::string&gt;&amp; outputs, <span class="keywordtype">float</span> iou_threshold,</div><div class="line"><a name="l00555"></a><span class="lineno">  555</span>&#160;                     <span class="keywordtype">float</span> confidence_threshold, <span class="keywordtype">size_t</span> max_boxes, <span class="keywordtype">bool</span> per_class_supression);</div><div class="line"><a name="l00556"></a><span class="lineno">  556</span>&#160;</div><div class="line"><a name="l00557"></a><span class="lineno">  557</span>&#160; <span class="keyword">private</span>:</div><div class="line"><a name="l00558"></a><span class="lineno">  558</span>&#160;  std::unique_ptr&lt;CoreML::Specification::NeuralNetwork&gt; impl_;</div><div class="line"><a name="l00559"></a><span class="lineno">  559</span>&#160;};</div><div class="line"><a name="l00560"></a><span class="lineno">  560</span>&#160;<span class="comment"></span></div><div class="line"><a name="l00561"></a><span class="lineno">  561</span>&#160;<span class="comment">/**</span></div><div class="line"><a name="l00562"></a><span class="lineno">  562</span>&#160;<span class="comment"> * Simple wrapper around CoreML::Specification::Pipeline that allows client code</span></div><div class="line"><a name="l00563"></a><span class="lineno">  563</span>&#160;<span class="comment"> * to pass around instances without importing full protobuf headers.</span></div><div class="line"><a name="l00564"></a><span class="lineno">  564</span>&#160;<span class="comment"> *</span></div><div class="line"><a name="l00565"></a><span class="lineno">  565</span>&#160;<span class="comment"> * \todo As needed, elaborate this class and move into its own file.</span></div><div class="line"><a name="l00566"></a><span class="lineno">  566</span>&#160;<span class="comment"> */</span></div><div class="line"><a name="l00567"></a><span class="lineno"><a class="line" href="classturi_1_1neural__net_1_1pipeline__spec.html">  567</a></span>&#160;<span class="keyword">class </span><a class="code" href="classturi_1_1neural__net_1_1pipeline__spec.html">pipeline_spec</a> {</div><div class="line"><a name="l00568"></a><span class="lineno">  568</span>&#160; <span class="keyword">public</span>:</div><div class="line"><a name="l00569"></a><span class="lineno">  569</span>&#160;  <a class="code" href="classturi_1_1neural__net_1_1pipeline__spec.html">pipeline_spec</a>(std::unique_ptr&lt;CoreML::Specification::Pipeline&gt; impl);</div><div class="line"><a name="l00570"></a><span class="lineno">  570</span>&#160;</div><div class="line"><a name="l00571"></a><span class="lineno">  571</span>&#160;  <a class="code" href="classturi_1_1neural__net_1_1pipeline__spec.html">pipeline_spec</a>(<a class="code" href="classturi_1_1neural__net_1_1pipeline__spec.html">pipeline_spec</a>&amp;&amp;);</div><div class="line"><a name="l00572"></a><span class="lineno">  572</span>&#160;  <a class="code" href="classturi_1_1neural__net_1_1pipeline__spec.html">pipeline_spec</a>&amp; operator=(<a class="code" href="classturi_1_1neural__net_1_1pipeline__spec.html">pipeline_spec</a>&amp;&amp;);</div><div class="line"><a name="l00573"></a><span class="lineno">  573</span>&#160;</div><div class="line"><a name="l00574"></a><span class="lineno">  574</span>&#160;  <span class="comment">// Declared here and defined in the .cpp file just to prevent the implicit</span></div><div class="line"><a name="l00575"></a><span class="lineno">  575</span>&#160;  <span class="comment">// default destructor from attempting (and failing) to instantiate</span></div><div class="line"><a name="l00576"></a><span class="lineno">  576</span>&#160;  <span class="comment">// std::unique_ptr&lt;Pipeline&gt;::~unique_ptr()</span></div><div class="line"><a name="l00577"></a><span class="lineno">  577</span>&#160;  ~<a class="code" href="classturi_1_1neural__net_1_1pipeline__spec.html">pipeline_spec</a>();</div><div class="line"><a name="l00578"></a><span class="lineno">  578</span>&#160;<span class="comment"></span></div><div class="line"><a name="l00579"></a><span class="lineno">  579</span>&#160;<span class="comment">  /**</span></div><div class="line"><a name="l00580"></a><span class="lineno">  580</span>&#160;<span class="comment">   * Exposes the underlying CoreML proto.</span></div><div class="line"><a name="l00581"></a><span class="lineno">  581</span>&#160;<span class="comment">   */</span></div><div class="line"><a name="l00582"></a><span class="lineno"><a class="line" href="classturi_1_1neural__net_1_1pipeline__spec.html#a4fc810ea05fd5b6cab0b1578e2cd493d">  582</a></span>&#160;  <span class="keyword">const</span> CoreML::Specification::Pipeline&amp; <a class="code" href="classturi_1_1neural__net_1_1pipeline__spec.html#a4fc810ea05fd5b6cab0b1578e2cd493d">get_coreml_spec</a>()<span class="keyword"> const </span>{</div><div class="line"><a name="l00583"></a><span class="lineno">  583</span>&#160;    <span class="keywordflow">return</span> *impl_;</div><div class="line"><a name="l00584"></a><span class="lineno">  584</span>&#160;  }</div><div class="line"><a name="l00585"></a><span class="lineno">  585</span>&#160;<span class="comment"></span></div><div class="line"><a name="l00586"></a><span class="lineno">  586</span>&#160;<span class="comment">  /**</span></div><div class="line"><a name="l00587"></a><span class="lineno">  587</span>&#160;<span class="comment">   * Transfer ownership of the underlying CoreML proto, invalidating the current</span></div><div class="line"><a name="l00588"></a><span class="lineno">  588</span>&#160;<span class="comment">   * instance (leaving it in a &quot;moved-from&quot; state).</span></div><div class="line"><a name="l00589"></a><span class="lineno">  589</span>&#160;<span class="comment">   *</span></div><div class="line"><a name="l00590"></a><span class="lineno">  590</span>&#160;<span class="comment">   * (Note that this method may only be invoked from a pipeline_spec&amp;&amp;)</span></div><div class="line"><a name="l00591"></a><span class="lineno">  591</span>&#160;<span class="comment">   */</span></div><div class="line"><a name="l00592"></a><span class="lineno">  592</span>&#160;  std::unique_ptr&lt;CoreML::Specification::Pipeline&gt; move_coreml_spec() &amp;&amp;;</div><div class="line"><a name="l00593"></a><span class="lineno">  593</span>&#160;</div><div class="line"><a name="l00594"></a><span class="lineno">  594</span>&#160; <span class="keyword">private</span>:</div><div class="line"><a name="l00595"></a><span class="lineno">  595</span>&#160;  std::unique_ptr&lt;CoreML::Specification::Pipeline&gt; impl_;</div><div class="line"><a name="l00596"></a><span class="lineno">  596</span>&#160;};</div><div class="line"><a name="l00597"></a><span class="lineno">  597</span>&#160;</div><div class="line"><a name="l00598"></a><span class="lineno">  598</span>&#160;}  <span class="comment">// neural_net</span></div><div class="line"><a name="l00599"></a><span class="lineno">  599</span>&#160;}  <span class="comment">// turi</span></div><div class="line"><a name="l00600"></a><span class="lineno">  600</span>&#160;</div><div class="line"><a name="l00601"></a><span class="lineno">  601</span>&#160;<span class="preprocessor">#endif  // UNITY_TOOLKITS_NEURAL_NET_MODEL_SPEC_HPP_</span></div><div class="ttc" id="structturi_1_1neural__net_1_1lstm__weight__initializers_html"><div class="ttname"><a href="structturi_1_1neural__net_1_1lstm__weight__initializers.html">turi::neural_net::lstm_weight_initializers</a></div><div class="ttdef"><b>Definition:</b> <a href="weight__init_8hpp_source.html#l00123">weight_init.hpp:123</a></div></div>
<div class="ttc" id="classturi_1_1neural__net_1_1model__spec_html"><div class="ttname"><a href="classturi_1_1neural__net_1_1model__spec.html">turi::neural_net::model_spec</a></div><div class="ttdef"><b>Definition:</b> <a href="model__spec_8hpp_source.html#l00040">model_spec.hpp:40</a></div></div>
<div class="ttc" id="classturi_1_1neural__net_1_1pipeline__spec_html_a4fc810ea05fd5b6cab0b1578e2cd493d"><div class="ttname"><a href="classturi_1_1neural__net_1_1pipeline__spec.html#a4fc810ea05fd5b6cab0b1578e2cd493d">turi::neural_net::pipeline_spec::get_coreml_spec</a></div><div class="ttdeci">const CoreML::Specification::Pipeline &amp; get_coreml_spec() const</div><div class="ttdef"><b>Definition:</b> <a href="model__spec_8hpp_source.html#l00582">model_spec.hpp:582</a></div></div>
<div class="ttc" id="classturi_1_1neural__net_1_1model__spec_html_a4d8bdc11e8d0b74a416a9ccfba8cb4c8"><div class="ttname"><a href="classturi_1_1neural__net_1_1model__spec.html#a4d8bdc11e8d0b74a416a9ccfba8cb4c8">turi::neural_net::model_spec::get_coreml_spec</a></div><div class="ttdeci">const CoreML::Specification::NeuralNetwork &amp; get_coreml_spec() const</div><div class="ttdef"><b>Definition:</b> <a href="model__spec_8hpp_source.html#l00088">model_spec.hpp:88</a></div></div>
<div class="ttc" id="classturi_1_1neural__net_1_1model__spec_html_a972ab38f4986dabfac28beaee2ae01ce"><div class="ttname"><a href="classturi_1_1neural__net_1_1model__spec.html#a972ab38f4986dabfac28beaee2ae01ce">turi::neural_net::model_spec::padding_policy</a></div><div class="ttdeci">padding_policy</div><div class="ttdef"><b>Definition:</b> <a href="model__spec_8hpp_source.html#l00050">model_spec.hpp:50</a></div></div>
<div class="ttc" id="namespaceturi_html"><div class="ttname"><a href="namespaceturi.html">turi</a></div><div class="ttdoc">SKD. </div><div class="ttdef"><b>Definition:</b> <a href="capi__initialization_8hpp_source.html#l00011">capi_initialization.hpp:11</a></div></div>
<div class="ttc" id="classturi_1_1neural__net_1_1model__spec_html_a0d1aa5b0fcc3c11248e0a2e33c49ff4f"><div class="ttname"><a href="classturi_1_1neural__net_1_1model__spec.html#a0d1aa5b0fcc3c11248e0a2e33c49ff4f">turi::neural_net::model_spec::padding_type</a></div><div class="ttdeci">padding_type</div><div class="ttdef"><b>Definition:</b> <a href="model__spec_8hpp_source.html#l00044">model_spec.hpp:44</a></div></div>
<div class="ttc" id="classturi_1_1neural__net_1_1model__spec_html_ae6369ecdfff80b58bc29d092960d7248"><div class="ttname"><a href="classturi_1_1neural__net_1_1model__spec.html#ae6369ecdfff80b58bc29d092960d7248">turi::neural_net::model_spec::pooling_type</a></div><div class="ttdeci">pooling_type</div><div class="ttdef"><b>Definition:</b> <a href="model__spec_8hpp_source.html#l00057">model_spec.hpp:57</a></div></div>
<div class="ttc" id="classturi_1_1neural__net_1_1pipeline__spec_html"><div class="ttname"><a href="classturi_1_1neural__net_1_1pipeline__spec.html">turi::neural_net::pipeline_spec</a></div><div class="ttdef"><b>Definition:</b> <a href="model__spec_8hpp_source.html#l00567">model_spec.hpp:567</a></div></div>
<div class="ttc" id="namespaceCoreML_html"><div class="ttname"><a href="namespaceCoreML.html">CoreML</a></div><div class="ttdef"><b>Definition:</b> <a href="model__spec_8hpp_source.html#l00022">model_spec.hpp:22</a></div></div>
</div><!-- fragment --></div><!-- contents -->
</div><!-- doc-content -->
<!-- start footer part -->
<div id="nav-path" class="navpath"><!-- id is needed for treeview function! -->
  <ul>
    <li class="navelem"><a class="el" href="dir_1c3a59615ddebb5fbf04127ce013cb9e.html">ml</a></li><li class="navelem"><a class="el" href="dir_6622307f3bbe65e3345569d508c646bb.html">neural_net</a></li><li class="navelem"><b>model_spec.hpp</b></li>
    <li class="footer">Generated by
    <a href="http://www.doxygen.org/index.html">
    <img class="footer" src="doxygen.png" alt="doxygen"/></a> 1.8.13 </li>
  </ul>
</div>
</body>
</html>
