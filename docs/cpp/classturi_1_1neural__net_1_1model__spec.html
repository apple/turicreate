<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.8.11"/>
<title>Turi Create: turi::neural_net::model_spec Class Reference</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="navtree.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="resize.js"></script>
<script type="text/javascript" src="navtreedata.js"></script>
<script type="text/javascript" src="navtree.js"></script>
<script type="text/javascript">
  $(document).ready(initResizable);
  $(window).load(resizeHeight);
</script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<script type="text/javascript">
  $(document).ready(function() { init_search(); });
</script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  <td id="projectalign" style="padding-left: 0.5em;">
   <div id="projectname">Turi Create
   &#160;<span id="projectnumber">4.0</span>
   </div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.8.11 -->
<script type="text/javascript">
var searchBox = new SearchBox("searchBox", "search",false,'Search');
</script>
  <div id="navrow1" class="tabs">
    <ul class="tablist">
      <li><a href="index.html"><span>Main&#160;Page</span></a></li>
      <li><a href="pages.html"><span>Related&#160;Pages</span></a></li>
      <li><a href="modules.html"><span>Modules</span></a></li>
      <li><a href="namespaces.html"><span>Namespaces</span></a></li>
      <li class="current"><a href="annotated.html"><span>Classes</span></a></li>
      <li><a href="files.html"><span>Files</span></a></li>
      <li><a href="examples.html"><span>Examples</span></a></li>
      <li>
        <div id="MSearchBox" class="MSearchBoxInactive">
        <span class="left">
          <img id="MSearchSelect" src="search/mag_sel.png"
               onmouseover="return searchBox.OnSearchSelectShow()"
               onmouseout="return searchBox.OnSearchSelectHide()"
               alt=""/>
          <input type="text" id="MSearchField" value="Search" accesskey="S"
               onfocus="searchBox.OnSearchFieldFocus(true)" 
               onblur="searchBox.OnSearchFieldFocus(false)" 
               onkeyup="searchBox.OnSearchFieldChange(event)"/>
          </span><span class="right">
            <a id="MSearchClose" href="javascript:searchBox.CloseResultsWindow()"><img id="MSearchCloseImg" border="0" src="search/close.png" alt=""/></a>
          </span>
        </div>
      </li>
    </ul>
  </div>
  <div id="navrow2" class="tabs2">
    <ul class="tablist">
      <li><a href="annotated.html"><span>Class&#160;List</span></a></li>
      <li><a href="classes.html"><span>Class&#160;Index</span></a></li>
      <li><a href="hierarchy.html"><span>Class&#160;Hierarchy</span></a></li>
      <li><a href="functions.html"><span>Class&#160;Members</span></a></li>
    </ul>
  </div>
</div><!-- top -->
<div id="side-nav" class="ui-resizable side-nav-resizable">
  <div id="nav-tree">
    <div id="nav-tree-contents">
      <div id="nav-sync" class="sync"></div>
    </div>
  </div>
  <div id="splitbar" style="-moz-user-select:none;" 
       class="ui-resizable-handle">
  </div>
</div>
<script type="text/javascript">
$(document).ready(function(){initNavTree('classturi_1_1neural__net_1_1model__spec.html','');});
</script>
<div id="doc-content">
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

<div class="header">
  <div class="summary">
<a href="#pub-types">Public Types</a> &#124;
<a href="#pub-methods">Public Member Functions</a> &#124;
<a href="classturi_1_1neural__net_1_1model__spec-members.html">List of all members</a>  </div>
  <div class="headertitle">
<div class="title">turi::neural_net::model_spec Class Reference</div>  </div>
</div><!--header-->
<div class="contents">

<p><code>#include &lt;<a class="el" href="model__spec_8hpp_source.html">ml/neural_net/model_spec.hpp</a>&gt;</code></p>
<table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a name="pub-types"></a>
Public Types</h2></td></tr>
</table><table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a name="pub-methods"></a>
Public Member Functions</h2></td></tr>
<tr class="memitem:af1ff523b7e54fe4869bc6cbee430afaa"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classturi_1_1neural__net_1_1model__spec.html#af1ff523b7e54fe4869bc6cbee430afaa">model_spec</a> ()</td></tr>
<tr class="separator:af1ff523b7e54fe4869bc6cbee430afaa"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:afe558dd5f6c1480738de3da6e82c0d11"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classturi_1_1neural__net_1_1model__spec.html#afe558dd5f6c1480738de3da6e82c0d11">model_spec</a> (const CoreML::Specification::NeuralNetwork &amp;nn_model)</td></tr>
<tr class="separator:afe558dd5f6c1480738de3da6e82c0d11"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a7b0e02b00b3e555b59928311a0318439"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classturi_1_1neural__net_1_1model__spec.html#a7b0e02b00b3e555b59928311a0318439">model_spec</a> (const std::string &amp;mlmodel_path)</td></tr>
<tr class="separator:a7b0e02b00b3e555b59928311a0318439"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a3775e8fc38066e8516ada6751b7f054b"><td class="memItemLeft" align="right" valign="top">const CoreML::Specification::NeuralNetwork &amp;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classturi_1_1neural__net_1_1model__spec.html#a3775e8fc38066e8516ada6751b7f054b">get_coreml_spec</a> () const </td></tr>
<tr class="separator:a3775e8fc38066e8516ada6751b7f054b"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:acd529f8eaf81a24965c424f331cacb24"><td class="memItemLeft" align="right" valign="top">std::unique_ptr&lt; CoreML::Specification::NeuralNetwork &gt;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classturi_1_1neural__net_1_1model__spec.html#acd529f8eaf81a24965c424f331cacb24">move_coreml_spec</a> ()&amp;&amp;</td></tr>
<tr class="separator:acd529f8eaf81a24965c424f331cacb24"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a26ad351e337f3cc1aeeef2a1cd12fcb5"><td class="memItemLeft" align="right" valign="top">float_array_map&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classturi_1_1neural__net_1_1model__spec.html#a26ad351e337f3cc1aeeef2a1cd12fcb5">export_params_view</a> () const </td></tr>
<tr class="separator:a26ad351e337f3cc1aeeef2a1cd12fcb5"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aec2f3705367eac080429f63f2623166c"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classturi_1_1neural__net_1_1model__spec.html#aec2f3705367eac080429f63f2623166c">update_params</a> (const float_array_map &amp;weights)</td></tr>
<tr class="separator:aec2f3705367eac080429f63f2623166c"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:af96893504d042d7f4fdf654f1bcdf853"><td class="memItemLeft" align="right" valign="top">bool&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classturi_1_1neural__net_1_1model__spec.html#af96893504d042d7f4fdf654f1bcdf853">has_layer_output</a> (const std::string &amp;layer_name) const </td></tr>
<tr class="separator:af96893504d042d7f4fdf654f1bcdf853"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:afa970eb6f824e6cf77d4de223594bd3b"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classturi_1_1neural__net_1_1model__spec.html#afa970eb6f824e6cf77d4de223594bd3b">add_relu</a> (const std::string &amp;name, const std::string &amp;input)</td></tr>
<tr class="separator:afa970eb6f824e6cf77d4de223594bd3b"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:acb6626db8f0340e548cff0bd05ac0ad4"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classturi_1_1neural__net_1_1model__spec.html#acb6626db8f0340e548cff0bd05ac0ad4">add_leakyrelu</a> (const std::string &amp;name, const std::string &amp;input, float alpha)</td></tr>
<tr class="separator:acb6626db8f0340e548cff0bd05ac0ad4"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a18df584c6e1eef1cf34fbcb043e935dd"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classturi_1_1neural__net_1_1model__spec.html#a18df584c6e1eef1cf34fbcb043e935dd">add_sigmoid</a> (const std::string &amp;name, const std::string &amp;input)</td></tr>
<tr class="separator:a18df584c6e1eef1cf34fbcb043e935dd"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aafcbd879d251f3e3ffff3432b25b5df4"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classturi_1_1neural__net_1_1model__spec.html#aafcbd879d251f3e3ffff3432b25b5df4">add_pooling</a> (const std::string &amp;name, const std::string &amp;input, size_t kernel_height, size_t kernel_width, size_t stride_h, size_t stride_w, <a class="el" href="classturi_1_1neural__net_1_1model__spec.html#a0d1aa5b0fcc3c11248e0a2e33c49ff4f">padding_type</a> padding, bool use_poolexcludepadding=false)</td></tr>
<tr class="separator:aafcbd879d251f3e3ffff3432b25b5df4"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a7ccd214f01f5f7d61ed0a22a090b8751"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classturi_1_1neural__net_1_1model__spec.html#a7ccd214f01f5f7d61ed0a22a090b8751">add_convolution</a> (const std::string &amp;name, const std::string &amp;input, size_t num_output_channels, size_t num_kernel_channels, size_t kernel_height, size_t kernel_width, size_t stride_h, size_t stride_w, <a class="el" href="classturi_1_1neural__net_1_1model__spec.html#a0d1aa5b0fcc3c11248e0a2e33c49ff4f">padding_type</a> padding, weight_initializer weight_initializer_fn, weight_initializer bias_initializer_fn=nullptr)</td></tr>
<tr class="separator:a7ccd214f01f5f7d61ed0a22a090b8751"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ae27a34b655ddb62438532c050d233eb5"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classturi_1_1neural__net_1_1model__spec.html#ae27a34b655ddb62438532c050d233eb5">add_padding</a> (const std::string &amp;name, const std::string &amp;input, size_t padding_top, size_t padding_bottom, size_t padding_left, size_t padding_right)</td></tr>
<tr class="separator:ae27a34b655ddb62438532c050d233eb5"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a54185bc37553c8ea489b2f062e5d58d6"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classturi_1_1neural__net_1_1model__spec.html#a54185bc37553c8ea489b2f062e5d58d6">add_upsampling</a> (const std::string &amp;name, const std::string &amp;input, size_t scaling_x, size_t scaling_y)</td></tr>
<tr class="separator:a54185bc37553c8ea489b2f062e5d58d6"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a5265c68c0395de316c21f0c12ce699e3"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classturi_1_1neural__net_1_1model__spec.html#a5265c68c0395de316c21f0c12ce699e3">add_inner_product</a> (const std::string &amp;name, const std::string &amp;input, size_t num_output_channels, size_t num_input_channels, weight_initializer weight_initializer_fn, weight_initializer bias_initializer_fn=nullptr)</td></tr>
<tr class="separator:a5265c68c0395de316c21f0c12ce699e3"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a583420894fa2754f703fa1933ba88f11"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classturi_1_1neural__net_1_1model__spec.html#a583420894fa2754f703fa1933ba88f11">add_batchnorm</a> (const std::string &amp;name, const std::string &amp;input, size_t num_channels, float epsilon)</td></tr>
<tr class="separator:a583420894fa2754f703fa1933ba88f11"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ab27561c305aa88745d19e5ea44294d52"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classturi_1_1neural__net_1_1model__spec.html#ab27561c305aa88745d19e5ea44294d52">add_instancenorm</a> (const std::string &amp;name, const std::string &amp;input, size_t num_channels, float epsilon)</td></tr>
<tr class="separator:ab27561c305aa88745d19e5ea44294d52"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a58b191a4c24d2c4efb49c48ac8eb0ea0"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classturi_1_1neural__net_1_1model__spec.html#a58b191a4c24d2c4efb49c48ac8eb0ea0">add_channel_concat</a> (const std::string &amp;name, const std::vector&lt; std::string &gt; &amp;inputs)</td></tr>
<tr class="separator:a58b191a4c24d2c4efb49c48ac8eb0ea0"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a903131139a2277c91efae7e68916f13a"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classturi_1_1neural__net_1_1model__spec.html#a903131139a2277c91efae7e68916f13a">add_softmax</a> (const std::string &amp;name, const std::string &amp;input)</td></tr>
<tr class="separator:a903131139a2277c91efae7e68916f13a"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a4a12f8427abded091d6b9bc25758e217"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classturi_1_1neural__net_1_1model__spec.html#a4a12f8427abded091d6b9bc25758e217">add_flatten</a> (const std::string &amp;name, const std::string &amp;input)</td></tr>
<tr class="separator:a4a12f8427abded091d6b9bc25758e217"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a1e1623161bae417d84204c4e9b965c3b"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classturi_1_1neural__net_1_1model__spec.html#a1e1623161bae417d84204c4e9b965c3b">add_addition</a> (const std::string &amp;name, const std::vector&lt; std::string &gt; &amp;inputs)</td></tr>
<tr class="separator:a1e1623161bae417d84204c4e9b965c3b"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a3a17edc293d3f7bf22cc32ac23183ade"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classturi_1_1neural__net_1_1model__spec.html#a3a17edc293d3f7bf22cc32ac23183ade">add_multiplication</a> (const std::string &amp;name, const std::vector&lt; std::string &gt; &amp;inputs)</td></tr>
<tr class="separator:a3a17edc293d3f7bf22cc32ac23183ade"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a87f4589de4b9fa9ae4733a6229dd6c0e"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classturi_1_1neural__net_1_1model__spec.html#a87f4589de4b9fa9ae4733a6229dd6c0e">add_exp</a> (const std::string &amp;name, const std::string &amp;input)</td></tr>
<tr class="separator:a87f4589de4b9fa9ae4733a6229dd6c0e"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a6c69a0731e05e63c9a8f7545381ac730"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classturi_1_1neural__net_1_1model__spec.html#a6c69a0731e05e63c9a8f7545381ac730">add_scale</a> (const std::string &amp;name, const std::string &amp;input, const std::vector&lt; size_t &gt; &amp;shape_c_h_w, weight_initializer scale_initializer_fn)</td></tr>
<tr class="separator:a6c69a0731e05e63c9a8f7545381ac730"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a4f0880d0964b3c08382d7c018c46824d"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classturi_1_1neural__net_1_1model__spec.html#a4f0880d0964b3c08382d7c018c46824d">add_constant</a> (const std::string &amp;name, const std::array&lt; size_t, 3 &gt; &amp;shape_c_h_w, weight_initializer weight_initializer_fn)</td></tr>
<tr class="separator:a4f0880d0964b3c08382d7c018c46824d"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a575b67647ae4cbf2be46a01438b05c8b"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classturi_1_1neural__net_1_1model__spec.html#a575b67647ae4cbf2be46a01438b05c8b">add_reshape</a> (const std::string &amp;name, const std::string &amp;input, const std::array&lt; size_t, 4 &gt; &amp;seq_c_h_w)</td></tr>
<tr class="separator:a575b67647ae4cbf2be46a01438b05c8b"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a722e25fe02cf66dcea3694b68df5bd46"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classturi_1_1neural__net_1_1model__spec.html#a722e25fe02cf66dcea3694b68df5bd46">add_permute</a> (const std::string &amp;name, const std::string &amp;input, const std::array&lt; size_t, 4 &gt; &amp;axis_permutation)</td></tr>
<tr class="separator:a722e25fe02cf66dcea3694b68df5bd46"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ac18acd609ede2684ef4bd9a3d0af2e8c"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classturi_1_1neural__net_1_1model__spec.html#ac18acd609ede2684ef4bd9a3d0af2e8c">add_channel_slice</a> (const std::string &amp;name, const std::string &amp;input, int start_index, int end_index, size_t stride)</td></tr>
<tr class="separator:ac18acd609ede2684ef4bd9a3d0af2e8c"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ab1990723baf0aeabc62ab8eb3616bfab"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classturi_1_1neural__net_1_1model__spec.html#ab1990723baf0aeabc62ab8eb3616bfab">add_lstm</a> (const std::string &amp;name, const std::string &amp;input, const std::string &amp;hidden_input, const std::string &amp;cell_input, const std::string &amp;hidden_output, const std::string &amp;cell_output, size_t input_vector_size, size_t output_vector_size, float cell_clip_threshold, const <a class="el" href="structturi_1_1neural__net_1_1lstm__weight__initializers.html">lstm_weight_initializers</a> &amp;initializers)</td></tr>
<tr class="separator:ab1990723baf0aeabc62ab8eb3616bfab"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aea11bb9b939367688ecab3b89179b085"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classturi_1_1neural__net_1_1model__spec.html#aea11bb9b939367688ecab3b89179b085">add_preprocessing</a> (const std::string &amp;feature_name, const float image_scale)</td></tr>
<tr class="separator:aea11bb9b939367688ecab3b89179b085"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table>
<a name="details" id="details"></a><h2 class="groupheader">Detailed Description</h2>
<div class="textblock"><p>Representation for a neural-network model (structure and parameters), optimized for convenient export to CoreML.</p>
<p>This class just wraps CoreML::Specification::NeuralNetwork, helping to insulate toolkits from protobuf code. </p>

<p>Definition at line <a class="el" href="model__spec_8hpp_source.html#l00039">39</a> of file <a class="el" href="model__spec_8hpp_source.html">model_spec.hpp</a>.</p>
</div><h2 class="groupheader">Member Enumeration Documentation</h2>
<a class="anchor" id="a0d1aa5b0fcc3c11248e0a2e33c49ff4f"></a>
<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">enum <a class="el" href="classturi_1_1neural__net_1_1model__spec.html#a0d1aa5b0fcc3c11248e0a2e33c49ff4f">turi::neural_net::model_spec::padding_type</a></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">strong</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<p>Parameter for convolution and pooling layers. </p>

<p>Definition at line <a class="el" href="model__spec_8hpp_source.html#l00043">43</a> of file <a class="el" href="model__spec_8hpp_source.html">model_spec.hpp</a>.</p>

</div>
</div>
<h2 class="groupheader">Constructor &amp; Destructor Documentation</h2>
<a class="anchor" id="af1ff523b7e54fe4869bc6cbee430afaa"></a>
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">turi::neural_net::model_spec::model_spec </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<p>Creates an empty <a class="el" href="classturi_1_1neural__net_1_1model__spec.html">model_spec</a> (with no layers). </p>

</div>
</div>
<a class="anchor" id="afe558dd5f6c1480738de3da6e82c0d11"></a>
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">turi::neural_net::model_spec::model_spec </td>
          <td>(</td>
          <td class="paramtype">const CoreML::Specification::NeuralNetwork &amp;&#160;</td>
          <td class="paramname"><em>nn_model</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<p>Initializes a <a class="el" href="classturi_1_1neural__net_1_1model__spec.html">model_spec</a> from a NeuralNetwork proto. </p>

</div>
</div>
<a class="anchor" id="a7b0e02b00b3e555b59928311a0318439"></a>
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">turi::neural_net::model_spec::model_spec </td>
          <td>(</td>
          <td class="paramtype">const std::string &amp;&#160;</td>
          <td class="paramname"><em>mlmodel_path</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<p>Initializes a <a class="el" href="classturi_1_1neural__net_1_1model__spec.html">model_spec</a> from the top-level NeuralNetwork found inside a CoreML model specification on disk.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">mlmodel_path</td><td>Path to a CoreM::Specification::Model proto on disk. </td></tr>
  </table>
  </dd>
</dl>
<dl class="exception"><dt>Exceptions</dt><dd>
  <table class="exception">
    <tr><td class="paramname">If</td><td>the indicated path could not be read or parsed. </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<h2 class="groupheader">Member Function Documentation</h2>
<a class="anchor" id="a1e1623161bae417d84204c4e9b965c3b"></a>
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void turi::neural_net::model_spec::add_addition </td>
          <td>(</td>
          <td class="paramtype">const std::string &amp;&#160;</td>
          <td class="paramname"><em>name</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const std::vector&lt; std::string &gt; &amp;&#160;</td>
          <td class="paramname"><em>inputs</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<p>Appends a layer that performs elementwise addition.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">name</td><td>The name of the layer and its output </td></tr>
    <tr><td class="paramname">inputs</td><td>The names of the layer's inputs </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a class="anchor" id="a583420894fa2754f703fa1933ba88f11"></a>
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void turi::neural_net::model_spec::add_batchnorm </td>
          <td>(</td>
          <td class="paramtype">const std::string &amp;&#160;</td>
          <td class="paramname"><em>name</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const std::string &amp;&#160;</td>
          <td class="paramname"><em>input</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">size_t&#160;</td>
          <td class="paramname"><em>num_channels</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">float&#160;</td>
          <td class="paramname"><em>epsilon</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<p>Appends a batch norm layer.</p>
<p>The beta and mean parameters are initialized to 0.f; the gamma and variance parameters are initialized to 1.f</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">name</td><td>The name of the layer and its output </td></tr>
    <tr><td class="paramname">input</td><td>The name of the layer's input </td></tr>
    <tr><td class="paramname">num_channels</td><td>The C dimension of the input and output </td></tr>
    <tr><td class="paramname">epsilon</td><td>Added to the variance for each input before normalizing </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a class="anchor" id="a58b191a4c24d2c4efb49c48ac8eb0ea0"></a>
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void turi::neural_net::model_spec::add_channel_concat </td>
          <td>(</td>
          <td class="paramtype">const std::string &amp;&#160;</td>
          <td class="paramname"><em>name</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const std::vector&lt; std::string &gt; &amp;&#160;</td>
          <td class="paramname"><em>inputs</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<p>Appends a layer that concatenates its inputs along the channel axis.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">name</td><td>The name of the layer and its output </td></tr>
    <tr><td class="paramname">inputs</td><td>The names of the layer's inputs </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a class="anchor" id="ac18acd609ede2684ef4bd9a3d0af2e8c"></a>
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void turi::neural_net::model_spec::add_channel_slice </td>
          <td>(</td>
          <td class="paramtype">const std::string &amp;&#160;</td>
          <td class="paramname"><em>name</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const std::string &amp;&#160;</td>
          <td class="paramname"><em>input</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>start_index</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>end_index</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">size_t&#160;</td>
          <td class="paramname"><em>stride</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<p>Appends a layer that slices the input along the channel axis.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">name</td><td>The name of the layer and its output </td></tr>
    <tr><td class="paramname">input</td><td>The name of the layer's input </td></tr>
    <tr><td class="paramname">start_index</td><td>The first channel to include </td></tr>
    <tr><td class="paramname">end_index</td><td>The first channel to stop including. If negative, then the number of channels is added first (so -1 becomes n - 1). </td></tr>
    <tr><td class="paramname">stride</td><td>The interval between channels to include </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a class="anchor" id="a4f0880d0964b3c08382d7c018c46824d"></a>
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void turi::neural_net::model_spec::add_constant </td>
          <td>(</td>
          <td class="paramtype">const std::string &amp;&#160;</td>
          <td class="paramname"><em>name</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const std::array&lt; size_t, 3 &gt; &amp;&#160;</td>
          <td class="paramname"><em>shape_c_h_w</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">weight_initializer&#160;</td>
          <td class="paramname"><em>weight_initializer_fn</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<p>Appends a layer with fixed values.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">name</td><td>The name of the layer and its output </td></tr>
    <tr><td class="paramname">shape_c_h_w</td><td>The shape of the output </td></tr>
    <tr><td class="paramname">weight_initializer_fn</td><td>Callback used to initialize the weights </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a class="anchor" id="a7ccd214f01f5f7d61ed0a22a090b8751"></a>
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void turi::neural_net::model_spec::add_convolution </td>
          <td>(</td>
          <td class="paramtype">const std::string &amp;&#160;</td>
          <td class="paramname"><em>name</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const std::string &amp;&#160;</td>
          <td class="paramname"><em>input</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">size_t&#160;</td>
          <td class="paramname"><em>num_output_channels</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">size_t&#160;</td>
          <td class="paramname"><em>num_kernel_channels</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">size_t&#160;</td>
          <td class="paramname"><em>kernel_height</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">size_t&#160;</td>
          <td class="paramname"><em>kernel_width</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">size_t&#160;</td>
          <td class="paramname"><em>stride_h</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">size_t&#160;</td>
          <td class="paramname"><em>stride_w</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classturi_1_1neural__net_1_1model__spec.html#a0d1aa5b0fcc3c11248e0a2e33c49ff4f">padding_type</a>&#160;</td>
          <td class="paramname"><em>padding</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">weight_initializer&#160;</td>
          <td class="paramname"><em>weight_initializer_fn</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">weight_initializer&#160;</td>
          <td class="paramname"><em>bias_initializer_fn</em> = <code>nullptr</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<p>Appends a convolution layer.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">name</td><td>The name of the layer and its output </td></tr>
    <tr><td class="paramname">input</td><td>The name of the layer's input </td></tr>
    <tr><td class="paramname">num_output_channels</td><td>The number of distinct filters in this layer </td></tr>
    <tr><td class="paramname">num_kernel_channels</td><td>The number of input features per "pixel" </td></tr>
    <tr><td class="paramname">kernel_size</td><td>The height and width of the kernel </td></tr>
    <tr><td class="paramname">weight_initializer_fn</td><td>Callback used to initialize the conv weights </td></tr>
    <tr><td class="paramname">bias_initializer_fn</td><td>Callback used to initialize the conv bias. If nullptr, then no bias vector is set. </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a class="anchor" id="a87f4589de4b9fa9ae4733a6229dd6c0e"></a>
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void turi::neural_net::model_spec::add_exp </td>
          <td>(</td>
          <td class="paramtype">const std::string &amp;&#160;</td>
          <td class="paramname"><em>name</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const std::string &amp;&#160;</td>
          <td class="paramname"><em>input</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<p>Appends a layer that applies the unary function f(x) = e^x to its input.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">name</td><td>The name of the layer and its output </td></tr>
    <tr><td class="paramname">input</td><td>The name of the layer's input </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a class="anchor" id="a4a12f8427abded091d6b9bc25758e217"></a>
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void turi::neural_net::model_spec::add_flatten </td>
          <td>(</td>
          <td class="paramtype">const std::string &amp;&#160;</td>
          <td class="paramname"><em>name</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const std::string &amp;&#160;</td>
          <td class="paramname"><em>input</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<p>Appends a layer that performs flatten normalization (along channel axis).</p>
<p>currently only supports channel first flattening, which means if the input order is <code>[C, H, W]</code>, then output array will be <code>[C * H * W, 1, 1]</code>, still <code>C-major</code> orderring. No underlying array storage will be changed.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">name</td><td>The name of the layer and its output </td></tr>
    <tr><td class="paramname">input</td><td>The name of the layer's input </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a class="anchor" id="a5265c68c0395de316c21f0c12ce699e3"></a>
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void turi::neural_net::model_spec::add_inner_product </td>
          <td>(</td>
          <td class="paramtype">const std::string &amp;&#160;</td>
          <td class="paramname"><em>name</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const std::string &amp;&#160;</td>
          <td class="paramname"><em>input</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">size_t&#160;</td>
          <td class="paramname"><em>num_output_channels</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">size_t&#160;</td>
          <td class="paramname"><em>num_input_channels</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">weight_initializer&#160;</td>
          <td class="paramname"><em>weight_initializer_fn</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">weight_initializer&#160;</td>
          <td class="paramname"><em>bias_initializer_fn</em> = <code>nullptr</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<p>Appends an inner-product (dense, fully connected) layer.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">name</td><td>The name of the layer and its output </td></tr>
    <tr><td class="paramname">input</td><td>The name of the layer's input </td></tr>
    <tr><td class="paramname">num_output_channels</td><td>Size of the output vector </td></tr>
    <tr><td class="paramname">num_input_channels</td><td>Size of the input vector </td></tr>
    <tr><td class="paramname">weight_initializer_fn</td><td>Callback used to initialize the weights </td></tr>
    <tr><td class="paramname">bias_initializer_fn</td><td>Callback used to initialize the bias. If nullptr, then no bias vector is set. </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a class="anchor" id="ab27561c305aa88745d19e5ea44294d52"></a>
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void turi::neural_net::model_spec::add_instancenorm </td>
          <td>(</td>
          <td class="paramtype">const std::string &amp;&#160;</td>
          <td class="paramname"><em>name</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const std::string &amp;&#160;</td>
          <td class="paramname"><em>input</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">size_t&#160;</td>
          <td class="paramname"><em>num_channels</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">float&#160;</td>
          <td class="paramname"><em>epsilon</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<p>Appends an instance norm layer.</p>
<p>The beta is initialized to 0.f; the gamma is initialized to 1.f</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">name</td><td>The name of the layer and its output </td></tr>
    <tr><td class="paramname">input</td><td>The name of the layer's input </td></tr>
    <tr><td class="paramname">num_channels</td><td>The C dimension of the input and output </td></tr>
    <tr><td class="paramname">epsilon</td><td>Added to the variance for each input before normalizing </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a class="anchor" id="acb6626db8f0340e548cff0bd05ac0ad4"></a>
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void turi::neural_net::model_spec::add_leakyrelu </td>
          <td>(</td>
          <td class="paramtype">const std::string &amp;&#160;</td>
          <td class="paramname"><em>name</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const std::string &amp;&#160;</td>
          <td class="paramname"><em>input</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">float&#160;</td>
          <td class="paramname"><em>alpha</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<p>Appends a leaky ReLU activation layer.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">name</td><td>The name of the layer and its output </td></tr>
    <tr><td class="paramname">input</td><td>The name of the layer's input </td></tr>
    <tr><td class="paramname">alpha</td><td>Multiplied to negative inputs </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a class="anchor" id="ab1990723baf0aeabc62ab8eb3616bfab"></a>
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void turi::neural_net::model_spec::add_lstm </td>
          <td>(</td>
          <td class="paramtype">const std::string &amp;&#160;</td>
          <td class="paramname"><em>name</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const std::string &amp;&#160;</td>
          <td class="paramname"><em>input</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const std::string &amp;&#160;</td>
          <td class="paramname"><em>hidden_input</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const std::string &amp;&#160;</td>
          <td class="paramname"><em>cell_input</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const std::string &amp;&#160;</td>
          <td class="paramname"><em>hidden_output</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const std::string &amp;&#160;</td>
          <td class="paramname"><em>cell_output</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">size_t&#160;</td>
          <td class="paramname"><em>input_vector_size</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">size_t&#160;</td>
          <td class="paramname"><em>output_vector_size</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">float&#160;</td>
          <td class="paramname"><em>cell_clip_threshold</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="structturi_1_1neural__net_1_1lstm__weight__initializers.html">lstm_weight_initializers</a> &amp;&#160;</td>
          <td class="paramname"><em>initializers</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<p>Appends an LSTM layer.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">name</td><td>The name of the layer and its output </td></tr>
    <tr><td class="paramname">input</td><td>The name of the layer's input </td></tr>
    <tr><td class="paramname">hidden_input</td><td>The name of the initial hidden state </td></tr>
    <tr><td class="paramname">cell_input</td><td>The name of the initial cell state </td></tr>
    <tr><td class="paramname">hidden_output</td><td>The name of the resulting hidden state </td></tr>
    <tr><td class="paramname">cell_output</td><td>The name of the resulting cell state </td></tr>
    <tr><td class="paramname">input_vector_size</td><td>The size of the input vector </td></tr>
    <tr><td class="paramname">output_vector_size</td><td>The size of the output vector (hidden state and cell state) </td></tr>
    <tr><td class="paramname">cell_clip_threshold</td><td>Maximum magnitude of cell state values </td></tr>
    <tr><td class="paramname">initializers</td><td>LSTM weights </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a class="anchor" id="a3a17edc293d3f7bf22cc32ac23183ade"></a>
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void turi::neural_net::model_spec::add_multiplication </td>
          <td>(</td>
          <td class="paramtype">const std::string &amp;&#160;</td>
          <td class="paramname"><em>name</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const std::vector&lt; std::string &gt; &amp;&#160;</td>
          <td class="paramname"><em>inputs</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<p>Appends a layer that performs elementwise multiplication.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">name</td><td>The name of the layer and its output </td></tr>
    <tr><td class="paramname">inputs</td><td>The names of the layer's inputs </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a class="anchor" id="ae27a34b655ddb62438532c050d233eb5"></a>
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void turi::neural_net::model_spec::add_padding </td>
          <td>(</td>
          <td class="paramtype">const std::string &amp;&#160;</td>
          <td class="paramname"><em>name</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const std::string &amp;&#160;</td>
          <td class="paramname"><em>input</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">size_t&#160;</td>
          <td class="paramname"><em>padding_top</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">size_t&#160;</td>
          <td class="paramname"><em>padding_bottom</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">size_t&#160;</td>
          <td class="paramname"><em>padding_left</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">size_t&#160;</td>
          <td class="paramname"><em>padding_right</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<p>Appends a padding layer.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">name</td><td>The name of the layer and its output </td></tr>
    <tr><td class="paramname">input</td><td>The name of the layer's input </td></tr>
    <tr><td class="paramname">padding_top</td><td>The padding on the top </td></tr>
    <tr><td class="paramname">padding_bottom</td><td>The padding on the bottom </td></tr>
    <tr><td class="paramname">padding_left</td><td>The padding to the left </td></tr>
    <tr><td class="paramname">padding_right</td><td>The padding to the right </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a class="anchor" id="a722e25fe02cf66dcea3694b68df5bd46"></a>
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void turi::neural_net::model_spec::add_permute </td>
          <td>(</td>
          <td class="paramtype">const std::string &amp;&#160;</td>
          <td class="paramname"><em>name</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const std::string &amp;&#160;</td>
          <td class="paramname"><em>input</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const std::array&lt; size_t, 4 &gt; &amp;&#160;</td>
          <td class="paramname"><em>axis_permutation</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<p>Appends a layer that transposes the dimensions of its input</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">name</td><td>The name of the layer and its output </td></tr>
    <tr><td class="paramname">input</td><td>The name of the layer's input </td></tr>
    <tr><td class="paramname">axis_permutation</td><td>A permutation of [0, 1, 2, 3], describing how to rearrange the [Seq, C, H, W] input. </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a class="anchor" id="aafcbd879d251f3e3ffff3432b25b5df4"></a>
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void turi::neural_net::model_spec::add_pooling </td>
          <td>(</td>
          <td class="paramtype">const std::string &amp;&#160;</td>
          <td class="paramname"><em>name</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const std::string &amp;&#160;</td>
          <td class="paramname"><em>input</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">size_t&#160;</td>
          <td class="paramname"><em>kernel_height</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">size_t&#160;</td>
          <td class="paramname"><em>kernel_width</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">size_t&#160;</td>
          <td class="paramname"><em>stride_h</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">size_t&#160;</td>
          <td class="paramname"><em>stride_w</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classturi_1_1neural__net_1_1model__spec.html#a0d1aa5b0fcc3c11248e0a2e33c49ff4f">padding_type</a>&#160;</td>
          <td class="paramname"><em>padding</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">bool&#160;</td>
          <td class="paramname"><em>use_poolexcludepadding</em> = <code>false</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<p>Appends a pooling layer. By default, it's a max pooling layer. And it can only be max pooling TODO: be able to set other pooling types</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">use_poolexcludepadding</td><td>padded values are excluded from the count (denominator) when computing average pooling. </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a class="anchor" id="aea11bb9b939367688ecab3b89179b085"></a>
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void turi::neural_net::model_spec::add_preprocessing </td>
          <td>(</td>
          <td class="paramtype">const std::string &amp;&#160;</td>
          <td class="paramname"><em>feature_name</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const float&#160;</td>
          <td class="paramname"><em>image_scale</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<p>Appends a preprocessing layer Now only support image scaling preprocessing though. </p>

</div>
</div>
<a class="anchor" id="afa970eb6f824e6cf77d4de223594bd3b"></a>
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void turi::neural_net::model_spec::add_relu </td>
          <td>(</td>
          <td class="paramtype">const std::string &amp;&#160;</td>
          <td class="paramname"><em>name</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const std::string &amp;&#160;</td>
          <td class="paramname"><em>input</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<p>Appends a ReLU activation layer.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">name</td><td>The name of the layer and its output </td></tr>
    <tr><td class="paramname">input</td><td>The name of the layer's input </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a class="anchor" id="a575b67647ae4cbf2be46a01438b05c8b"></a>
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void turi::neural_net::model_spec::add_reshape </td>
          <td>(</td>
          <td class="paramtype">const std::string &amp;&#160;</td>
          <td class="paramname"><em>name</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const std::string &amp;&#160;</td>
          <td class="paramname"><em>input</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const std::array&lt; size_t, 4 &gt; &amp;&#160;</td>
          <td class="paramname"><em>seq_c_h_w</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<p>Appends a layer that reshapes its input.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">name</td><td>The name of the layer and its output </td></tr>
    <tr><td class="paramname">input</td><td>The name of the layer's input </td></tr>
    <tr><td class="paramname">shape_c_h_w</td><td>The shape of the output </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a class="anchor" id="a6c69a0731e05e63c9a8f7545381ac730"></a>
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void turi::neural_net::model_spec::add_scale </td>
          <td>(</td>
          <td class="paramtype">const std::string &amp;&#160;</td>
          <td class="paramname"><em>name</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const std::string &amp;&#160;</td>
          <td class="paramname"><em>input</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const std::vector&lt; size_t &gt; &amp;&#160;</td>
          <td class="paramname"><em>shape_c_h_w</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">weight_initializer&#160;</td>
          <td class="paramname"><em>scale_initializer_fn</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<p>Appends a layer that performs elementwise multiplication between its input and some fixed weights.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">name</td><td>The name of the layer and its output </td></tr>
    <tr><td class="paramname">input</td><td>The name of the layer's input </td></tr>
    <tr><td class="paramname">shape_c_h_w</td><td>The shape of the input and output </td></tr>
    <tr><td class="paramname">weight_initializer_fn</td><td>Callback used to initialize the weights </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a class="anchor" id="a18df584c6e1eef1cf34fbcb043e935dd"></a>
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void turi::neural_net::model_spec::add_sigmoid </td>
          <td>(</td>
          <td class="paramtype">const std::string &amp;&#160;</td>
          <td class="paramname"><em>name</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const std::string &amp;&#160;</td>
          <td class="paramname"><em>input</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<p>Appends a sigmoid activation layer.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">name</td><td>The name of the layer and its output </td></tr>
    <tr><td class="paramname">input</td><td>The name of the layer's input </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a class="anchor" id="a903131139a2277c91efae7e68916f13a"></a>
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void turi::neural_net::model_spec::add_softmax </td>
          <td>(</td>
          <td class="paramtype">const std::string &amp;&#160;</td>
          <td class="paramname"><em>name</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const std::string &amp;&#160;</td>
          <td class="paramname"><em>input</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<p>Appends a layer that performs softmax normalization (along channel axis).</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">name</td><td>The name of the layer and its output </td></tr>
    <tr><td class="paramname">input</td><td>The name of the layer's input </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a class="anchor" id="a54185bc37553c8ea489b2f062e5d58d6"></a>
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void turi::neural_net::model_spec::add_upsampling </td>
          <td>(</td>
          <td class="paramtype">const std::string &amp;&#160;</td>
          <td class="paramname"><em>name</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const std::string &amp;&#160;</td>
          <td class="paramname"><em>input</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">size_t&#160;</td>
          <td class="paramname"><em>scaling_x</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">size_t&#160;</td>
          <td class="paramname"><em>scaling_y</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<p>Appends an upsampling layer.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">name</td><td>The name of the layer and its output </td></tr>
    <tr><td class="paramname">input</td><td>The name of the layer's input </td></tr>
    <tr><td class="paramname">scaling_x</td><td>The upsample scale on the x axis </td></tr>
    <tr><td class="paramname">scaling_y</td><td>The upsample scale on the y axis </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a class="anchor" id="a26ad351e337f3cc1aeeef2a1cd12fcb5"></a>
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">float_array_map turi::neural_net::model_spec::export_params_view </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
</div><div class="memdoc">
<p>Creates a shared_float_array view (weak reference) into the parameters of the model, indexed by layer name.</p>
<dl class="section return"><dt>Returns</dt><dd>A dictionary whose keys are of the form "$layername_$paramname". The layer names are taken from the name field of each NeuralNetworkLayer containing a supported layer. The supported layers are ConvolutionLayerParams (with params "weight" (in NCHW order) and "bias") and BatchnormLayerParams (with params "gamma", "beta", "running_mean", and "running_var"). </dd></dl>
<dl class="exception"><dt>Exceptions</dt><dd>
  <table class="exception">
    <tr><td class="paramname">If</td><td>a NeuralNetworkLayer in the specification seems malformed (e.g. WeightParams with size inconsistent with declared layer shape).</td></tr>
  </table>
  </dd>
</dl>
<p>To avoid copying data, the data backing the shared_float_array instances in the return value will only remain valid for the lifetime of this instance! </p>

</div>
</div>
<a class="anchor" id="a3775e8fc38066e8516ada6751b7f054b"></a>
<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">const CoreML::Specification::NeuralNetwork&amp; turi::neural_net::model_spec::get_coreml_spec </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<p>Exposes the underlying CoreML proto. </p>

<p>Definition at line <a class="el" href="model__spec_8hpp_source.html#l00075">75</a> of file <a class="el" href="model__spec_8hpp_source.html">model_spec.hpp</a>.</p>

</div>
</div>
<a class="anchor" id="af96893504d042d7f4fdf654f1bcdf853"></a>
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">bool turi::neural_net::model_spec::has_layer_output </td>
          <td>(</td>
          <td class="paramtype">const std::string &amp;&#160;</td>
          <td class="paramname"><em>layer_name</em></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
</div><div class="memdoc">
<p>Determines whether the neural network contains a layer with the given output name.</p>
<p>In general, it is only safe to add a new layer that takes a named input if this method returns true for that name. </p>

</div>
</div>
<a class="anchor" id="acd529f8eaf81a24965c424f331cacb24"></a>
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">std::unique_ptr&lt;CoreML::Specification::NeuralNetwork&gt; turi::neural_net::model_spec::move_coreml_spec </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<p>Transfer ownership of the underlying CoreML proto, invalidating the current instance (leaving it in a "moved-from" state).</p>
<p>(Note that this method may only be invoked from a <a class="el" href="classturi_1_1neural__net_1_1model__spec.html">model_spec</a>&amp;&amp;) </p>

</div>
</div>
<a class="anchor" id="aec2f3705367eac080429f63f2623166c"></a>
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void turi::neural_net::model_spec::update_params </td>
          <td>(</td>
          <td class="paramtype">const float_array_map &amp;&#160;</td>
          <td class="paramname"><em>weights</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<p>Overwrites existing WeightParams values using the provided float_array values.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">weights</td><td>A dictionary whose keys follow the same naming scheme used by <code>export_params_view</code>. </td></tr>
  </table>
  </dd>
</dl>
<dl class="exception"><dt>Exceptions</dt><dd>
  <table class="exception">
    <tr><td class="paramname">If</td><td>a float_array's shape does not match the corresponding NeuralNetworkLayer. </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<hr/>The documentation for this class was generated from the following file:<ul>
<li>ml/neural_net/<a class="el" href="model__spec_8hpp_source.html">model_spec.hpp</a></li>
</ul>
</div><!-- contents -->
</div><!-- doc-content -->
<!-- start footer part -->
<div id="nav-path" class="navpath"><!-- id is needed for treeview function! -->
  <ul>
    <li class="navelem"><a class="el" href="namespaceturi.html">turi</a></li><li class="navelem"><b>neural_net</b></li><li class="navelem"><a class="el" href="classturi_1_1neural__net_1_1model__spec.html">model_spec</a></li>
    <li class="footer">Generated by
    <a href="http://www.doxygen.org/index.html">
    <img class="footer" src="doxygen.png" alt="doxygen"/></a> 1.8.11 </li>
  </ul>
</div>
</body>
</html>
